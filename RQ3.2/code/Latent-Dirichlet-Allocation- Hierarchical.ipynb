{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#K-Means import\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Benchmarking Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_hierarchical(estimator, name, data,labels=None):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%.2fs\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), \n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=None)))\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Fold 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This code runs Agglomerative clustering with TF-IDF model for phrase-rubric classification of keyphrases\n",
    "    \n",
    "* The training and testing for each of the phases is seperated.  \n",
    "\n",
    "* This can be modified using line ```traindata=pd.read_csv(\"../data/test1.tsv\",delimiter=\"\\t\")``` and ```traindata=pd.read_csv(\"../data/train1.tsv\",delimiter=\"\\t\")```\n",
    "\n",
    "* Since randomness impacts results, we search for randomness parameter using ```for rstate in [16]:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2)))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4,random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "data=lda.transform(X_train)\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "X_test=lda.transform(X_test)\n",
    "# Do K-Means\n",
    "for rstate in [37]:\n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_hierarchical(AgglomerativeClustering(n_clusters=4,\n",
    "                                    linkage=\"complete\", affinity=\"cosine\"), name=\"Cosine\", data=X_test,labels=Y_test)\n",
    "\n",
    "    km1_random=bench_hierarchical(AgglomerativeClustering(n_clusters=4,\n",
    "                                    linkage=\"complete\", affinity=\"euclidean\"), name=\"Euclidean\", data=X_test,labels=Y_test)\n",
    "    \n",
    "    km1_pca=bench_hierarchical(AgglomerativeClustering(n_clusters=4,\n",
    "                                    linkage=\"complete\", affinity=\"cityblock\"), name=\"city-block\", data=X_test,labels=Y_test)\n",
    "\n",
    "\n",
    "    \n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"Cosine Affinity\")\n",
    "    ypred=km1_km.labels_\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "    print(\"Euclidean Affinity\")\n",
    "    ypred=km1_random.labels_\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"City Block Affinity\")\n",
    "    ypred=km1_pca.labels_\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Fold 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This code runs Agglomerative clustering with TF-IDF model for phrase-rubric classification of keyphrases for fold-2\n",
    "    \n",
    "* The training and testing for each of the phases is seperated.  \n",
    "\n",
    "* This can be modified using line ```traindata=pd.read_csv(\"../data/test1.tsv\",delimiter=\"\\t\")``` and ```traindata=pd.read_csv(\"../data/train1.tsv\",delimiter=\"\\t\")```\n",
    "\n",
    "* Since randomness impacts results, we search for randomness parameter using ```for rstate in [16]:```\n",
    "\n",
    "* Latent dirichlet allocation is done using ```lda = LatentDirichletAllocation(n_components=4,random_state=42) lda.fit(X_train)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2)))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4,random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "data=lda.transform(X_train)\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "X_test=lda.transform(X_test)\n",
    "# print(labels)\n",
    "\n",
    "for rstate in [0]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_hierarchical(AgglomerativeClustering(n_clusters=4,\n",
    "                                    linkage=\"complete\", affinity=\"cosine\"), name=\"Cosine\", data=X_test,labels=Y_test)\n",
    "\n",
    "    km1_random=bench_hierarchical(AgglomerativeClustering(n_clusters=4,\n",
    "                                    linkage=\"complete\", affinity=\"euclidean\"), name=\"Euclidean\", data=X_test,labels=Y_test)\n",
    "    \n",
    "    km1_pca=bench_hierarchical(AgglomerativeClustering(n_clusters=4,\n",
    "                                    linkage=\"complete\", affinity=\"cityblock\"), name=\"city-block\", data=X_test,labels=Y_test)\n",
    "\n",
    "\n",
    "    \n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"Cosine Affinity\")\n",
    "    ypred=km1_km.labels_\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "    print(\"Euclidean Affinity\")\n",
    "    ypred=km1_random.labels_\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"City Block Affinity\")\n",
    "    ypred=km1_pca.labels_\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
