{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#K-Means import\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data,labels=None):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=None)))\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2)))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4,random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "data=lda.transform(X_train)\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "X_test=lda.transform(X_test)\n",
    "# Do K-Means\n",
    "for rstate in [27]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MeansFold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2)))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4,random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "data=lda.transform(X_train)\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "X_test=lda.transform(X_test)\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "# Do K-Means\n",
    "for rstate in [27]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Autoclustering with Elbow Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOld -1\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "\n",
    "\n",
    "distortions = []\n",
    "for i in range(1, 100):\n",
    "    km = KMeans(init='k-means++', n_clusters=i, n_init=10,random_state=rstate)\n",
    "    km.fit(data)\n",
    "    distortions.append(km.inertia_)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(1, 100), distortions, marker='-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means with Learnt BERT Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "modelfolder=\"../../RQ2.2/data/bert/fold1/\"\n",
    "\n",
    "X_train= pickle.load(open(modelfolder+'xtrain.pkl', 'rb'))\n",
    "Y_train= pickle.load(open(modelfolder+'ytrain.pkl', 'rb'))\n",
    "X_test= pickle.load(open(modelfolder+'xtest.pkl', 'rb'))\n",
    "Y_test= pickle.load(open(modelfolder+'ytest.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "for rstate in [23]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "modelfolder=\"../../RQ2.2/data/bert/fold2/\"\n",
    "\n",
    "X_train= pickle.load(open(modelfolder+'xtrain.pkl', 'rb'))\n",
    "Y_train= pickle.load(open(modelfolder+'ytrain.pkl', 'rb'))\n",
    "X_test= pickle.load(open(modelfolder+'xtest.pkl', 'rb'))\n",
    "Y_test= pickle.load(open(modelfolder+'ytest.pkl', 'rb'))\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "for rstate in [1]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
