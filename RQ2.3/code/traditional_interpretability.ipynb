{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.70000   0.36207   0.47727        58\n",
      "           2    0.61268   0.96667   0.75000        90\n",
      "           3    0.50000   0.08333   0.14286        12\n",
      "           4    0.50000   0.20833   0.29412        24\n",
      "\n",
      "    accuracy                        0.61957       184\n",
      "   macro avg    0.57817   0.40510   0.41606       184\n",
      "weighted avg    0.61816   0.61957   0.56497       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf', SGDClassifier(loss='log', penalty='l2',alpha=0.001, max_iter=100, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "ypred=clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,ypred,digits=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.58537   0.42857   0.49485        56\n",
      "           2    0.59677   0.82222   0.69159        90\n",
      "           3    0.00000   0.00000   0.00000        15\n",
      "           4    0.31579   0.26087   0.28571        23\n",
      "\n",
      "    accuracy                        0.56522       184\n",
      "   macro avg    0.37448   0.37792   0.36804       184\n",
      "weighted avg    0.50953   0.56522   0.52460       184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKANDAN\\Desktop\\dl2020-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "traindata=pd.read_csv(\"../data/tsv/train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "clf2 = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf', SGDClassifier(loss='log', penalty='l2',alpha=0.001, max_iter=100, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "\n",
    "clf2.fit(X_train,Y_train)\n",
    "ypred=clf2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,ypred,digits=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intepretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKANDAN\\Desktop\\dl2020-env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\MANIKANDAN\\Desktop\\dl2020-env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65385   0.60714   0.62963        56\n",
      "           1    0.62992   0.88889   0.73733        90\n",
      "           2    0.00000   0.00000   0.00000        15\n",
      "           3    0.66667   0.08696   0.15385        23\n",
      "\n",
      "    accuracy                        0.63043       184\n",
      "   macro avg    0.48761   0.39575   0.38020       184\n",
      "weighted avg    0.59044   0.63043   0.57151       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xtrain=pickle.load(open('../data/summary_pkl/xtrain.pkl', 'rb'))\n",
    "xtest=pickle.load(open('../data/summary_pkl/xtest.pkl', 'rb'))\n",
    "\n",
    "ytrain=pickle.load(open('../data/summary_pkl/ytrain.pkl', 'rb'))\n",
    "ytest=pickle.load(open('../data/summary_pkl/ytest.pkl', 'rb'))\n",
    "\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "\n",
    "xtraindict={}\n",
    "\n",
    "\n",
    "for i,j in zip(X_train,xtrain):\n",
    "    xtraindict[i]=j\n",
    "\n",
    "for i,j in zip(X_test,xtest):\n",
    "    xtraindict[i]=j\n",
    "\n",
    "def returnfeatures(text):\n",
    "    global xtraindict\n",
    "    res=[]\n",
    "    for i in text:\n",
    "        res.append(xtraindict[i])\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "clf11 = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=200, random_state=42,class_weight=\"balanced\",warm_start=True)  #Pipeline([('custom', FunctionTransformer(returnfeatures)),('clf', SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=200, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "clf11.fit(np.array(xtrain),np.array(ytrain))\n",
    "ypred=clf11.predict(xtest)\n",
    "print(classification_report(ytest,ypred,digits=5))\n",
    "\n",
    "\n",
    "clf12=XGBClassifier(n_estimators=200,random_state=10,max_depth=3,learning_rate =0.1)\n",
    "clf12.fit(np.array(xtrain),np.array(ytrain))\n",
    "ypred=clf12.predict(xtest)\n",
    "print(classification_report(ytest,ypred,digits=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "te = TextExplainer(random_state=42)\n",
    "\n",
    "#Change file names here\n",
    "traindata=pd.read_csv(\"../data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "X_test=np.array(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(X_test[i])\n",
    "    te.fit(X_test[i], clf11.predict_proba)\n",
    "    a=te.show_prediction(target_names=[1,2,3,4])\n",
    "    display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
