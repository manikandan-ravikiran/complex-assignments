{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPMINER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Not enough candidates to choose from (100 requested, 31 given)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.82609   0.90476       184\n",
      "\n",
      "    accuracy                        0.82609       184\n",
      "   macro avg    0.50000   0.41304   0.45238       184\n",
      "weighted avg    1.00000   0.82609   0.90476       184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKANDAN\\Desktop\\dl2020-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "# 1. create a KPMiner extractor.\n",
    "extractor = pke.unsupervised.KPMiner()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt',\n",
    "                        language='en',\n",
    "                        normalization=None)\n",
    "\n",
    "\n",
    "# 3. select {1-5}-grams that do not contain punctuation marks or\n",
    "#    stopwords as keyphrase candidates. Set the least allowable seen\n",
    "#    frequency to 5 and the number of words after which candidates are\n",
    "#    filtered out to 200.\n",
    "lasf = 5\n",
    "cutoff = 200\n",
    "extractor.candidate_selection(lasf=lasf, cutoff=cutoff)\n",
    "\n",
    "# 4. weight the candidates using KPMiner weighting function.\n",
    "df = pke.load_document_frequency_file(input_file='../data/df_kea_test.tsv.gz')\n",
    "alpha = 2.3\n",
    "sigma = 3.0\n",
    "extractor.candidate_weighting(df=df, alpha=alpha, sigma=sigma)\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "allkeyphrases=[]\n",
    "# print the n-highest (10) scored candidates\n",
    "for (keyphrase, score) in extractor.get_n_best(n=100, stemming=False):\n",
    "    allkeyphrases.append(keyphrase)\n",
    "\n",
    "df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "texts=df[\"text\"]\n",
    "texts=[i.replace(\",\",\"\") for i in texts]\n",
    "labels=df[\"label\"]\n",
    "labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "overall_evidence=[]\n",
    "removed_text=[]\n",
    "for txt in texts:\n",
    "    evidence=[]\n",
    "    for phr in allkeyphrases :\n",
    "        #print(phr,\"--\",txt, phr in txt)\n",
    "        if phr in txt and txt not in removed_text:\n",
    "            evidence.append(1)\n",
    "            removed_text.append(txt)\n",
    "    if evidence==[]:\n",
    "        evidence=[0]\n",
    "    overall_evidence.append(evidence)\n",
    "\n",
    "ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "print(ypred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels,ypred,digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAKE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         0\n",
      "           1    1.00000   0.94022   0.96919       184\n",
      "\n",
      "    accuracy                        0.94022       184\n",
      "   macro avg    0.50000   0.47011   0.48459       184\n",
      "weighted avg    1.00000   0.94022   0.96919       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 1. create a YAKE extractor.\n",
    "extractor = pke.unsupervised.YAKE()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt',\n",
    "                        language='en',\n",
    "                        normalization=None)\n",
    "\n",
    "\n",
    "# 3. select {1-3}-grams not containing punctuation marks and not\n",
    "#    beginning/ending with a stopword as candidates.\n",
    "stoplist = stopwords.words('english')\n",
    "extractor.candidate_selection(n=3, stoplist=stoplist)\n",
    "\n",
    "# 4. weight the candidates using YAKE weighting scheme, a window (in\n",
    "#    words) for computing left/right contexts can be specified.\n",
    "window = 2\n",
    "use_stems = False # use stems instead of words for weighting\n",
    "extractor.candidate_weighting(window=window,\n",
    "                              stoplist=stoplist,\n",
    "                              use_stems=use_stems)\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases.\n",
    "#    redundant keyphrases are removed from the output using levenshtein\n",
    "#    distance and a threshold.\n",
    "allkeyphrases=[]\n",
    "# print the n-highest (10) scored candidates\n",
    "for (keyphrase, score) in extractor.get_n_best(n=100, stemming=False):\n",
    "    allkeyphrases.append(keyphrase)\n",
    "\n",
    "df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "texts=df[\"text\"]\n",
    "texts=[i.replace(\",\",\"\") for i in texts]\n",
    "labels=df[\"label\"]\n",
    "labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "overall_evidence=[]\n",
    "removed_text=[]\n",
    "for txt in texts:\n",
    "    evidence=[]\n",
    "    for phr in allkeyphrases :\n",
    "        #print(phr,\"--\",txt, phr in txt)\n",
    "        if phr in txt and txt not in removed_text:\n",
    "            evidence.append(1)\n",
    "            removed_text.append(txt)\n",
    "    if evidence==[]:\n",
    "        evidence=[0]\n",
    "    overall_evidence.append(evidence)\n",
    "\n",
    "ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "print(ypred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels,ypred,digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
