{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44105691056910573\n",
      "0.469083888712578\n",
      "0.5588493010339575\n",
      "0.6067337729954877\n",
      "0.5620004633383529\n",
      "0.5723805997778602\n",
      "0.5788288288288288\n",
      "0.5738636363636364\n",
      "0.5796649547566642\n",
      "0.5771793318734566\n",
      "0.5887445887445887\n",
      "0.5886213386092747\n",
      "0.5915138207181607\n",
      "0.5915138207181607\n",
      "0.5855010453639324\n",
      "0.5855010453639324\n",
      "0.5855010453639324\n",
      "0.5883769360926722\n",
      "0.59705964669663\n",
      "0.6058333333333333\n",
      "0.6058333333333333\n",
      "0.6024942853301063\n",
      "0.5897192458971925\n",
      "0.578397212543554\n",
      "0.5771548753115003\n",
      "0.5799587951122478\n",
      "0.5799587951122478\n",
      "0.5827755466309683\n",
      "0.5757390929965557\n",
      "0.5757390929965557\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5713716108452951\n",
      "0.5741405381770482\n",
      "0.5741405381770482\n",
      "0.5741405381770482\n",
      "0.559465281997459\n",
      "0.559465281997459\n",
      "0.559465281997459\n",
      "0.559465281997459\n",
      "0.559465281997459\n",
      "0.5621667654028436\n",
      "0.5621667654028436\n",
      "0.5621667654028436\n",
      "0.5621667654028436\n",
      "0.5648815174698908\n",
      "0.5676100628930818\n",
      "0.5676100628930818\n",
      "0.5676100628930818\n",
      "0.56\n",
      "0.5626987732848705\n",
      "0.5626987732848705\n",
      "0.5626987732848705\n",
      "0.5681400337061437\n",
      "0.5708836617927526\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5629844961240309\n",
      "0.5549728011854393\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5630065151755919\n",
      "0.5630065151755919\n",
      "0.5630065151755919\n",
      "0.5630065151755919\n",
      "0.5630065151755919\n",
      "0.5630065151755919\n",
      "0.5547226386806597\n",
      "0.5547226386806597\n",
      "0.5547226386806597\n",
      "0.5547226386806597\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n",
      "0.5315930965133698\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "# this example uses TopicRank\n",
    "from pke.unsupervised import TopicRank\n",
    "from collections import Counter\n",
    "# create a TopicRank extractor\n",
    "extractor = TopicRank()\n",
    "\n",
    "# load the content of the document, here in CoreNLP XML format\n",
    "# the input language is set to English (used for the stoplist)\n",
    "# normalization is set to stemming (computed with Porter's stemming algorithm)\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt',\n",
    "                        language=\"en\",\n",
    "                        normalization='stemming')\n",
    "\n",
    "# select the keyphrase candidates, for TopicRank the longest sequences of \n",
    "# nouns and adjectives\n",
    "extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ'})\n",
    "\n",
    "# weight the candidates using a random walk. The threshold parameter sets the\n",
    "# minimum similarity for clustering, and the method parameter defines the \n",
    "# linkage method\n",
    "extractor.candidate_weighting(threshold=0.1,\n",
    "                              method='average')\n",
    "\n",
    "# print the n-highest (10) scored candidates\n",
    "\n",
    "kcounter={}\n",
    "for kk in range(1,200):\n",
    "    allkeyphrases=[]\n",
    "    for (keyphrase, score) in extractor.get_n_best(n=kk, stemming=False):\n",
    "        allkeyphrases.append(keyphrase)\n",
    "\n",
    "    df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "    texts=df[\"text\"]\n",
    "    texts=[i.replace(\",\",\"\") for i in texts]\n",
    "    labels=df[\"label\"]\n",
    "    labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "    overall_evidence=[]\n",
    "    removed_text=[]\n",
    "    for txt in texts:\n",
    "        evidence=[]\n",
    "        for phr in allkeyphrases :\n",
    "            #print(phr,\"--\",txt, phr in txt)\n",
    "            if phr in txt and txt not in removed_text:\n",
    "                evidence.append(1)\n",
    "                removed_text.append(txt)\n",
    "        if evidence==[]:\n",
    "            evidence=[0]\n",
    "        overall_evidence.append(evidence)\n",
    "\n",
    "    ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "    # print(ypred)\n",
    "\n",
    "    \n",
    "    f1s=(f1_score(labels,ypred,average='macro'))\n",
    "    kcounter[kk]=f1s\n",
    "\n",
    "    \n",
    "for index,(k,v) in enumerate(zip(kcounter.keys(),kcounter.values())):\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Candidates are generated using 0.33-top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25472047389855607\n",
      "0.260752688172043\n",
      "0.260752688172043\n",
      "0.26673148598282287\n",
      "0.26673148598282287\n",
      "0.27853258878189624\n",
      "0.2763157894736843\n",
      "0.28210999139552856\n",
      "0.28210999139552856\n",
      "0.28785498137802606\n",
      "0.29355161753820697\n",
      "0.29920074134136454\n",
      "0.29920074134136454\n",
      "0.29920074134136454\n",
      "0.30480317804261464\n",
      "0.30480317804261464\n",
      "0.30480317804261464\n",
      "0.30480317804261464\n",
      "0.30480317804261464\n",
      "0.30480317804261464\n",
      "0.31035973711518505\n",
      "0.31035973711518505\n",
      "0.31587121266590934\n",
      "0.32133838383838387\n",
      "0.32133838383838387\n",
      "0.3242857142857143\n",
      "0.32180073842820284\n",
      "0.32713098896096504\n",
      "0.32713098896096504\n",
      "0.32713098896096504\n",
      "0.33766859344894024\n",
      "0.3428773418168965\n",
      "0.3531781242517711\n",
      "0.3531781242517711\n",
      "0.35827147998200626\n",
      "0.3633276740237691\n",
      "0.3633276740237691\n",
      "0.3683473389355742\n",
      "0.3656419074780859\n",
      "0.3706039968739533\n",
      "0.3706039968739533\n",
      "0.37553112940750333\n",
      "0.38042389853137515\n",
      "0.37764665046858725\n",
      "0.3824850299401198\n",
      "0.3824850299401198\n",
      "0.4015151515151515\n",
      "0.4015151515151515\n",
      "0.4015151515151515\n",
      "0.4015151515151515\n",
      "0.4336547510263089\n",
      "0.4425852616686392\n",
      "0.43953804347826086\n",
      "0.4570215298063399\n",
      "0.4570215298063399\n",
      "0.4613306315433975\n",
      "0.46561589117996327\n",
      "0.46561589117996327\n",
      "0.46987773149458756\n",
      "0.474116569704805\n",
      "0.4810973569755771\n",
      "0.4810973569755771\n",
      "0.4851839965768079\n",
      "0.4851839965768079\n",
      "0.4892505444876472\n",
      "0.4892505444876472\n",
      "0.49329737235633414\n",
      "0.49329737235633414\n",
      "0.5265151515151516\n",
      "0.5340463835645453\n",
      "0.5377906592024986\n",
      "0.5377906592024986\n",
      "0.5415211178151793\n",
      "0.5415211178151793\n",
      "0.545238063739433\n",
      "0.545238063739433\n",
      "0.5416666666666666\n",
      "0.5416666666666666\n",
      "0.5381818181818182\n",
      "0.5381818181818182\n",
      "0.5381818181818182\n",
      "0.5381818181818182\n",
      "0.5381818181818182\n",
      "0.5765636614633111\n",
      "0.5800188576512928\n",
      "0.5834661989795918\n",
      "0.5834661989795918\n",
      "0.5795945496842805\n",
      "0.5830229836135348\n",
      "0.5830229836135348\n",
      "0.5830229836135348\n",
      "0.5830229836135348\n",
      "0.5881471972614464\n",
      "0.5881471972614464\n",
      "0.6197950553025374\n",
      "0.6197950553025374\n",
      "0.6230780713539334\n",
      "0.6188858695652175\n",
      "0.6188858695652175\n",
      "0.6147824653922216\n",
      "0.6147824653922216\n",
      "0.6147824653922216\n",
      "0.6147824653922216\n",
      "0.6179977719401999\n",
      "0.6179977719401999\n",
      "0.6179977719401999\n",
      "0.6179977719401999\n",
      "0.6179977719401999\n",
      "0.6124405880402344\n",
      "0.6124405880402344\n",
      "0.6124405880402344\n",
      "0.6124405880402344\n",
      "0.6124405880402344\n",
      "0.6080181564052531\n",
      "0.6080181564052531\n",
      "0.6080181564052531\n",
      "0.6080181564052531\n",
      "0.6164133388936024\n",
      "0.6164133388936024\n",
      "0.6164133388936024\n",
      "0.6164133388936024\n",
      "0.6164133388936024\n",
      "0.6195088204773435\n",
      "0.6195088204773435\n",
      "0.6195088204773435\n",
      "0.6195088204773435\n",
      "0.6146623329721921\n",
      "0.6146623329721921\n",
      "0.6146623329721921\n",
      "0.6177458589134714\n",
      "0.6208327890741789\n",
      "0.6208327890741789\n",
      "0.6313401393615297\n",
      "0.6344381425026586\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6375416512402814\n",
      "0.6355771950983458\n",
      "0.6355771950983458\n",
      "0.6355771950983458\n",
      "0.638676540850454\n",
      "0.6417823294255042\n",
      "0.6417823294255042\n",
      "0.6417823294255042\n",
      "0.6417823294255042\n",
      "0.6480145763375446\n",
      "0.651740904613749\n",
      "0.6548694779116466\n",
      "0.6548694779116466\n",
      "0.6548694779116466\n",
      "0.6524706179704285\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6443340944290984\n",
      "0.6474358974358975\n",
      "0.6505493091412119\n",
      "0.6505493091412119\n",
      "0.6505493091412119\n",
      "0.6505493091412119\n",
      "0.6568126934733635\n",
      "0.6568126934733635\n",
      "0.6568126934733635\n",
      "0.6568126934733635\n",
      "0.6568126934733635\n",
      "0.6663059163059163\n",
      "0.6694983618972358\n",
      "0.6677368130350732\n",
      "0.6677368130350732\n",
      "0.6677368130350732\n",
      "0.6709670706965614\n",
      "0.6709670706965614\n",
      "0.6709670706965614\n",
      "0.6709670706965614\n",
      "0.6709670706965614\n",
      "0.6709670706965614\n",
      "0.6709670706965614\n",
      "0.6646341463414633\n",
      "0.6614253552835233\n",
      "0.6614253552835233\n",
      "0.6614253552835233\n",
      "0.654919495943868\n",
      "0.6483375959079285\n",
      "0.641677822400714\n",
      "0.641677822400714\n",
      "0.641677822400714\n",
      "0.641677822400714\n",
      "0.641677822400714\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# this example uses TopicRank\n",
    "from pke.unsupervised import TopicRank\n",
    "from collections import Counter\n",
    "import pke\n",
    "# this example uses TopicRank\n",
    "pos = {'NOUN', 'PROPN', 'ADJ'}\n",
    "\n",
    "# 1. create a TextRank extractor.\n",
    "extractor = pke.unsupervised.TextRank()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt',\n",
    "                        language='en',\n",
    "                        normalization=None)\n",
    "\n",
    "# 3. build the graph representation of the document and rank the words.\n",
    "#    Keyphrase candidates are composed from the 33-percent\n",
    "#    highest-ranked words.\n",
    "extractor.candidate_weighting(window=2,\n",
    "                              pos=pos,\n",
    "                              top_percent=0.33)\n",
    "\n",
    "\n",
    "# print the n-highest (10) scored candidates\n",
    "\n",
    "\n",
    "kcounter={}\n",
    "for kk in range(1,200):\n",
    "    allkeyphrases=[]\n",
    "    for (keyphrase, score) in extractor.get_n_best(n=kk, stemming=False):\n",
    "        allkeyphrases.append(keyphrase)\n",
    "\n",
    "    df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "    texts=df[\"text\"]\n",
    "    texts=[i.replace(\",\",\"\") for i in texts]\n",
    "    labels=df[\"label\"]\n",
    "    labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "    overall_evidence=[]\n",
    "    removed_text=[]\n",
    "    for txt in texts:\n",
    "        evidence=[]\n",
    "        for phr in allkeyphrases :\n",
    "            #print(phr,\"--\",txt, phr in txt)\n",
    "            if phr in txt and txt not in removed_text:\n",
    "                evidence.append(1)\n",
    "                removed_text.append(txt)\n",
    "        if evidence==[]:\n",
    "            evidence=[0]\n",
    "        overall_evidence.append(evidence)\n",
    "\n",
    "    ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "    # print(ypred)\n",
    "\n",
    "    \n",
    "    f1s=(f1_score(labels,ypred,average='macro'))\n",
    "    kcounter[kk]=f1s\n",
    "\n",
    "    \n",
    "for index,(k,v) in enumerate(zip(kcounter.keys(),kcounter.values())):\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25472047389855607\n",
      "0.25262909133876876\n",
      "0.25862907146329606\n",
      "0.2645762313388974\n",
      "0.2645762313388974\n",
      "0.2704715003883979\n",
      "0.2704715003883979\n",
      "0.2704715003883979\n",
      "0.2763157894736843\n",
      "0.2763157894736843\n",
      "0.28210999139552856\n",
      "0.44923627430036317\n",
      "0.45733333333333337\n",
      "0.45733333333333337\n",
      "0.4613519167477248\n",
      "0.4613519167477248\n",
      "0.4699235626453972\n",
      "0.4699235626453972\n",
      "0.4699235626453972\n",
      "0.4738520408163266\n",
      "0.48165551661888073\n",
      "0.4855311865621144\n",
      "0.4855311865621144\n",
      "0.4855311865621144\n",
      "0.4820954907161804\n",
      "0.48594042079306377\n",
      "0.48594042079306377\n",
      "0.48976887192536045\n",
      "0.48976887192536045\n",
      "0.48976887192536045\n",
      "0.49785646236900605\n",
      "0.5015809178584185\n",
      "0.5015809178584185\n",
      "0.5015809178584185\n",
      "0.5015809178584185\n",
      "0.5052910052910053\n",
      "0.5089870253541244\n",
      "0.5126692763436309\n",
      "0.5199936528086322\n",
      "0.5236363636363637\n",
      "0.5236363636363637\n",
      "0.5308842781766969\n",
      "0.5308842781766969\n",
      "0.5344900550148117\n",
      "0.5308098242272745\n",
      "0.5308098242272745\n",
      "0.5271164021164021\n",
      "0.5271164021164021\n",
      "0.5306856817790948\n",
      "0.5306856817790948\n",
      "0.5306856817790948\n",
      "0.5306856817790948\n",
      "0.5342436752408173\n",
      "0.5342436752408173\n",
      "0.5342436752408173\n",
      "0.5342436752408173\n",
      "0.5342436752408173\n",
      "0.5377906592024986\n",
      "0.5377906592024986\n",
      "0.5413269088213492\n",
      "0.5605624800255673\n",
      "0.5605624800255673\n",
      "0.5605624800255673\n",
      "0.5639515516529201\n",
      "0.56\n",
      "0.5633697581021762\n",
      "0.5633697581021762\n",
      "0.5667325357829524\n",
      "0.5667325357829524\n",
      "0.5667325357829524\n",
      "0.5667325357829524\n",
      "0.570088587806149\n",
      "0.570088587806149\n",
      "0.5834506239862736\n",
      "0.5867768595041323\n",
      "0.5900978930830278\n",
      "0.5900978930830278\n",
      "0.598344693281402\n",
      "0.598344693281402\n",
      "0.598344693281402\n",
      "0.598344693281402\n",
      "0.5972421797280867\n",
      "0.6004068584713746\n",
      "0.6035706365047684\n",
      "0.5990975355779243\n",
      "0.5990975355779243\n",
      "0.6022474410324877\n",
      "0.6022474410324877\n",
      "0.5917366946778712\n",
      "0.5917366946778712\n",
      "0.5917366946778712\n",
      "0.5948448834696712\n",
      "0.5948448834696712\n",
      "0.5948448834696712\n",
      "0.5979532163742689\n",
      "0.5933155871044069\n",
      "0.5933155871044069\n",
      "0.5933155871044069\n",
      "0.5933155871044069\n",
      "0.5964100248363062\n",
      "0.5964100248363062\n",
      "0.5964100248363062\n",
      "0.5995051254860375\n",
      "0.5995051254860375\n",
      "0.5995051254860375\n",
      "0.5948090218746458\n",
      "0.5948090218746458\n",
      "0.5948090218746458\n",
      "0.5978904331284338\n",
      "0.5978904331284338\n",
      "0.5978904331284338\n",
      "0.5679120111731842\n",
      "0.5788288288288288\n",
      "0.5788288288288288\n",
      "0.5788288288288288\n",
      "0.5817584965893177\n",
      "0.584692521444968\n",
      "0.5793005255903425\n",
      "0.5793005255903425\n",
      "0.5793005255903425\n",
      "0.5822192513368983\n",
      "0.5880716556615309\n",
      "0.5880716556615309\n",
      "0.5880716556615309\n",
      "0.5880716556615309\n",
      "0.5972014460234356\n",
      "0.609029445216732\n",
      "0.609029445216732\n",
      "0.6120067849273156\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.6179884717942168\n",
      "0.6179884717942168\n",
      "0.6179884717942168\n",
      "0.6179884717942168\n",
      "0.6121794871794872\n",
      "0.6121794871794872\n",
      "0.6121794871794872\n",
      "0.6121794871794872\n",
      "0.6121794871794872\n",
      "0.6121794871794872\n",
      "0.6121794871794872\n",
      "0.6151618974086763\n",
      "0.6151618974086763\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6181542237148024\n",
      "0.6241702459976571\n",
      "0.6241702459976571\n",
      "0.6241702459976571\n",
      "0.6241702459976571\n",
      "0.6241702459976571\n",
      "0.6241702459976571\n",
      "0.6271947733768886\n",
      "0.6212121212121212\n",
      "0.6212121212121212\n",
      "0.6212121212121212\n",
      "0.6212121212121212\n",
      "0.6212121212121212\n",
      "0.6242241648968571\n",
      "0.6272480825178525\n",
      "0.6211555378512507\n",
      "0.6211555378512507\n",
      "0.6211555378512507\n",
      "0.6211555378512507\n",
      "0.6150000000000001\n",
      "0.6150000000000001\n",
      "0.6087800632646572\n",
      "0.6087800632646572\n",
      "0.6087800632646572\n",
      "0.6087800632646572\n",
      "0.6087800632646572\n",
      "0.6087800632646572\n",
      "0.6083683710836837\n",
      "0.6083683710836837\n",
      "0.6113239676458067\n",
      "0.6142925561029009\n",
      "0.6142925561029009\n",
      "0.6142925561029009\n",
      "0.6142925561029009\n",
      "0.6142925561029009\n",
      "0.6142925561029009\n",
      "0.6012841756420878\n",
      "0.6012841756420878\n",
      "0.6012841756420878\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "\n",
    "# define the set of valid Part-of-Speeches\n",
    "pos = {'NOUN', 'PROPN', 'ADJ'}\n",
    "\n",
    "# 1. create a SingleRank extractor.\n",
    "extractor = pke.unsupervised.SingleRank()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt',\n",
    "                        language='en',\n",
    "                        normalization=None)\n",
    "\n",
    "# 3. select the longest sequences of nouns and adjectives as candidates.\n",
    "extractor.candidate_selection(pos=pos)\n",
    "\n",
    "# 4. weight the candidates using the sum of their word's scores that are\n",
    "#    computed using random walk. In the graph, nodes are words of\n",
    "#    certain part-of-speech (nouns and adjectives) that are connected if\n",
    "#    they occur in a window of 10 words.\n",
    "extractor.candidate_weighting(window=10,\n",
    "                              pos=pos)\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "kcounter={}\n",
    "for kk in range(1,200):\n",
    "    allkeyphrases=[]\n",
    "    for (keyphrase, score) in extractor.get_n_best(n=kk, stemming=False):\n",
    "        allkeyphrases.append(keyphrase)\n",
    "\n",
    "    df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "    texts=df[\"text\"]\n",
    "    texts=[i.replace(\",\",\"\") for i in texts]\n",
    "    labels=df[\"label\"]\n",
    "    labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "    overall_evidence=[]\n",
    "    removed_text=[]\n",
    "    for txt in texts:\n",
    "        evidence=[]\n",
    "        for phr in allkeyphrases :\n",
    "            #print(phr,\"--\",txt, phr in txt)\n",
    "            if phr in txt and txt not in removed_text:\n",
    "                evidence.append(1)\n",
    "                removed_text.append(txt)\n",
    "        if evidence==[]:\n",
    "            evidence=[0]\n",
    "        overall_evidence.append(evidence)\n",
    "\n",
    "    ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "    # print(ypred)\n",
    "\n",
    "    \n",
    "    f1s=(f1_score(labels,ypred,average='macro'))\n",
    "    kcounter[kk]=f1s\n",
    "\n",
    "    \n",
    "for index,(k,v) in enumerate(zip(kcounter.keys(),kcounter.values())):\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSITION RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25472047389855607\n",
      "0.260752688172043\n",
      "0.26673148598282287\n",
      "0.27265781121429405\n",
      "0.27265781121429405\n",
      "0.27265781121429405\n",
      "0.4451570663139188\n",
      "0.4451570663139188\n",
      "0.44923627430036317\n",
      "0.4459565838103244\n",
      "0.4459565838103244\n",
      "0.4540233713973537\n",
      "0.4540233713973537\n",
      "0.4540233713973537\n",
      "0.46201141853315764\n",
      "0.46597680357522875\n",
      "0.46597680357522875\n",
      "0.46597680357522875\n",
      "0.4748010610079576\n",
      "0.4786487955560858\n",
      "0.4786487955560858\n",
      "0.4786487955560858\n",
      "0.48247985581000846\n",
      "0.49009324009324007\n",
      "0.49009324009324007\n",
      "0.49009324009324007\n",
      "0.49009324009324007\n",
      "0.49387619993379683\n",
      "0.5013962229192309\n",
      "0.5013962229192309\n",
      "0.5013962229192309\n",
      "0.5013962229192309\n",
      "0.5051339049433683\n",
      "0.5051339049433683\n",
      "0.5126692763436309\n",
      "0.5163380542441914\n",
      "0.5199936528086322\n",
      "0.5199936528086322\n",
      "0.5199936528086322\n",
      "0.5199936528086322\n",
      "0.5236363636363637\n",
      "0.5236363636363637\n",
      "0.5199936528086322\n",
      "0.5163380542441914\n",
      "0.5163380542441914\n",
      "0.5163380542441914\n",
      "0.5163380542441914\n",
      "0.5318152798467759\n",
      "0.5352071439027961\n",
      "0.5385906040268457\n",
      "0.5419659156018068\n",
      "0.5453333333333334\n",
      "0.5453333333333334\n",
      "0.5486931113156945\n",
      "0.5486931113156945\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5520455030976287\n",
      "0.5553907617482396\n",
      "0.5653862637951355\n",
      "0.5687055133309205\n",
      "0.5687055133309205\n",
      "0.5687055133309205\n",
      "0.5687055133309205\n",
      "0.5720188902007085\n",
      "0.5679410224388672\n",
      "0.571236559139785\n",
      "0.571236559139785\n",
      "0.571236559139785\n",
      "0.571236559139785\n",
      "0.5745267661343487\n",
      "0.5745267661343487\n",
      "0.5868840817218398\n",
      "0.5868840817218398\n",
      "0.5825641025641025\n",
      "0.6040067664863202\n",
      "0.6040067664863202\n",
      "0.6071428571428572\n",
      "0.6102793640993981\n",
      "0.6102793640993981\n",
      "0.6102793640993981\n",
      "0.6102793640993981\n",
      "0.6134165542060279\n",
      "0.6165546964127266\n",
      "0.6165546964127266\n",
      "0.6165546964127266\n",
      "0.6165546964127266\n",
      "0.6056983858832214\n",
      "0.6115819209039548\n",
      "0.6115819209039548\n",
      "0.6115819209039548\n",
      "0.6115819209039548\n",
      "0.6146623329721921\n",
      "0.6146623329721921\n",
      "0.6146623329721921\n",
      "0.6146623329721921\n",
      "0.6301169590643275\n",
      "0.6301169590643275\n",
      "0.6301169590643275\n",
      "0.6301169590643275\n",
      "0.6301169590643275\n",
      "0.6301169590643275\n",
      "0.6301169590643275\n",
      "0.6332204780958244\n",
      "0.6282473257317504\n",
      "0.6313401393615297\n",
      "0.6344381425026586\n",
      "0.6375416512402814\n",
      "0.6437664716129897\n",
      "0.6468884376493073\n",
      "0.6417823294255042\n",
      "0.6417823294255042\n",
      "0.6417823294255042\n",
      "0.6521904761904762\n",
      "0.6469185619955978\n",
      "0.6469185619955978\n",
      "0.6469185619955978\n",
      "0.6469185619955978\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.6120067849273156\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.614992999872725\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6092065975825894\n",
      "0.6121794871794872\n",
      "0.6151618974086763\n",
      "0.6151618974086763\n",
      "0.6181542237148024\n",
      "0.6211568694186479\n",
      "0.6211568694186479\n",
      "0.6241702459976571\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6271947733768886\n",
      "0.6332790042969328\n",
      "0.6332790042969328\n",
      "0.6332790042969328\n",
      "0.6363395927003439\n",
      "0.6394131022921543\n",
      "0.6394131022921543\n",
      "0.6333333333333333\n",
      "0.6333333333333333\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6271904132286733\n",
      "0.6209829232217292\n",
      "0.6239935180027346\n",
      "0.6239935180027346\n",
      "0.6239935180027346\n",
      "0.6239935180027346\n",
      "0.6176929336769293\n",
      "0.6206896551724137\n",
      "0.6206896551724137\n",
      "0.6206896551724137\n",
      "0.6028954383886256\n",
      "0.6028954383886256\n",
      "0.6028954383886256\n",
      "0.6028954383886256\n",
      "0.6028954383886256\n",
      "0.6028954383886256\n",
      "0.6028954383886256\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "\n",
    "# define the valid Part-of-Speeches to occur in the graph\n",
    "pos = {'NOUN', 'PROPN', 'ADJ'}\n",
    "\n",
    "# define the grammar for selecting the keyphrase candidates\n",
    "grammar = \"NP: {<ADJ>*<NOUN|PROPN>+}\"\n",
    "\n",
    "# 1. create a PositionRank extractor.\n",
    "extractor = pke.unsupervised.PositionRank()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt',\n",
    "                        language='en',\n",
    "                        normalization=None)\n",
    "\n",
    "# 3. select the noun phrases up to 3 words as keyphrase candidates.\n",
    "extractor.candidate_selection(grammar=grammar,\n",
    "                              maximum_word_number=5)\n",
    "\n",
    "# 4. weight the candidates using the sum of their word's scores that are\n",
    "#    computed using random walk biaised with the position of the words\n",
    "#    in the document. In the graph, nodes are words (nouns and\n",
    "#    adjectives only) that are connected if they occur in a window of\n",
    "#    10 words.\n",
    "extractor.candidate_weighting(window=10,\n",
    "                              pos=pos)\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "kcounter={}\n",
    "for kk in range(1,200):\n",
    "    allkeyphrases=[]\n",
    "    for (keyphrase, score) in extractor.get_n_best(n=kk, stemming=False):\n",
    "        allkeyphrases.append(keyphrase)\n",
    "\n",
    "    df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "    texts=df[\"text\"]\n",
    "    texts=[i.replace(\",\",\"\") for i in texts]\n",
    "    labels=df[\"label\"]\n",
    "    labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "    overall_evidence=[]\n",
    "    removed_text=[]\n",
    "    for txt in texts:\n",
    "        evidence=[]\n",
    "        for phr in allkeyphrases :\n",
    "            #print(phr,\"--\",txt, phr in txt)\n",
    "            if phr in txt and txt not in removed_text:\n",
    "                evidence.append(1)\n",
    "                removed_text.append(txt)\n",
    "        if evidence==[]:\n",
    "            evidence=[0]\n",
    "        overall_evidence.append(evidence)\n",
    "\n",
    "    ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "    # print(ypred)\n",
    "\n",
    "    \n",
    "    f1s=(f1_score(labels,ypred,average='macro'))\n",
    "    kcounter[kk]=f1s\n",
    "\n",
    "    \n",
    "for index,(k,v) in enumerate(zip(kcounter.keys(),kcounter.values())):\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTIPARTITE RANKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33401143078562434\n",
      "0.469083888712578\n",
      "0.5346373702514358\n",
      "0.6067337729954877\n",
      "0.6259775586535193\n",
      "0.6259775586535193\n",
      "0.6322313455371651\n",
      "0.6319250465549349\n",
      "0.6350391576368329\n",
      "0.6350391576368329\n",
      "0.6263145456693844\n",
      "0.6283783783783783\n",
      "0.6345294188715719\n",
      "0.5799923634975181\n",
      "0.5828609749477078\n",
      "0.5915138207181607\n",
      "0.6002449979583504\n",
      "0.6002449979583504\n",
      "0.6031746031746033\n",
      "0.6031746031746033\n",
      "0.6061144860967057\n",
      "0.5995748882826492\n",
      "0.5995748882826492\n",
      "0.5995748882826492\n",
      "0.5995748882826492\n",
      "0.5995748882826492\n",
      "0.5961411860029371\n",
      "0.5961411860029371\n",
      "0.5961411860029371\n",
      "0.6048850574712644\n",
      "0.6048850574712644\n",
      "0.6048850574712644\n",
      "0.6048850574712644\n",
      "0.5917909417288042\n",
      "0.5917909417288042\n",
      "0.5917909417288042\n",
      "0.5917909417288042\n",
      "0.5851323934869688\n",
      "0.5851323934869688\n",
      "0.5851323934869688\n",
      "0.5908382782824836\n",
      "0.5908382782824836\n",
      "0.5785326625917311\n",
      "0.5785326625917311\n",
      "0.5785326625917311\n",
      "0.5785326625917311\n",
      "0.5813397129186604\n",
      "0.5841607608081765\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.586996336996337\n",
      "0.5797197517906792\n",
      "0.5825311018957346\n",
      "0.5825311018957346\n",
      "0.5825311018957346\n",
      "0.5825311018957346\n",
      "0.5825311018957346\n",
      "0.5825311018957346\n",
      "0.5825311018957346\n",
      "0.5853576813536606\n",
      "0.5853576813536606\n",
      "0.5853576813536606\n",
      "0.5853576813536606\n",
      "0.5853576813536606\n",
      "0.588200059898173\n",
      "0.588200059898173\n",
      "0.588200059898173\n",
      "0.5731107072542784\n",
      "0.5731107072542784\n",
      "0.5731107072542784\n",
      "0.5731107072542784\n",
      "0.5654119304659089\n",
      "0.5654119304659089\n",
      "0.5654119304659089\n",
      "0.5681400337061437\n",
      "0.5681400337061437\n",
      "0.5681400337061437\n",
      "0.5681400337061437\n",
      "0.5681400337061437\n",
      "0.5681400337061437\n",
      "0.5681400337061437\n",
      "0.5708836617927526\n",
      "0.5708836617927526\n",
      "0.5708836617927526\n",
      "0.5629844961240309\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5656963481448264\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5576349654739485\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5603126665482323\n",
      "0.5520816780549818\n",
      "0.5520816780549818\n",
      "0.5520816780549818\n",
      "0.5520816780549818\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.543728135932034\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.546314179945276\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5489155748162249\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5403212654924984\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n",
      "0.5251617466558489\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 1. create a MultipartiteRank extractor.\n",
    "extractor = pke.unsupervised.MultipartiteRank()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input='../../RQ1.1/train_data/document/test/test.txt')\n",
    "\n",
    "# 3. select the longest sequences of nouns and adjectives, that do\n",
    "#    not contain punctuation marks or stopwords as candidates.\n",
    "pos = {'NOUN', 'PROPN', 'ADJ'}\n",
    "stoplist = list(string.punctuation)\n",
    "stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "stoplist += stopwords.words('english')\n",
    "extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
    "\n",
    "# 4. build the Multipartite graph and rank candidates using random walk,\n",
    "#    alpha controls the weight adjustment mechanism, see TopicRank for\n",
    "#    threshold/method parameters.\n",
    "extractor.candidate_weighting(alpha=1.1,\n",
    "                              threshold=0.74,\n",
    "                              method='average')\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "kcounter={}\n",
    "for kk in range(1,200):\n",
    "    allkeyphrases=[]\n",
    "    for (keyphrase, score) in extractor.get_n_best(n=kk, stemming=False):\n",
    "        allkeyphrases.append(keyphrase)\n",
    "\n",
    "    df=pd.read_csv(\"../../RQ1.1/train_data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "    texts=df[\"text\"]\n",
    "    texts=[i.replace(\",\",\"\") for i in texts]\n",
    "    labels=df[\"label\"]\n",
    "    labels=[0 if i==0 else 1 for i in labels]\n",
    "\n",
    "    overall_evidence=[]\n",
    "    removed_text=[]\n",
    "    for txt in texts:\n",
    "        evidence=[]\n",
    "        for phr in allkeyphrases :\n",
    "            #print(phr,\"--\",txt, phr in txt)\n",
    "            if phr in txt and txt not in removed_text:\n",
    "                evidence.append(1)\n",
    "                removed_text.append(txt)\n",
    "        if evidence==[]:\n",
    "            evidence=[0]\n",
    "        overall_evidence.append(evidence)\n",
    "\n",
    "    ypred=[Counter(i).most_common(1)[0][0] for i in overall_evidence]\n",
    "    # print(ypred)\n",
    "\n",
    "    \n",
    "    f1s=(f1_score(labels,ypred,average='macro'))\n",
    "    kcounter[kk]=f1s\n",
    "\n",
    "    \n",
    "for index,(k,v) in enumerate(zip(kcounter.keys(),kcounter.values())):\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
