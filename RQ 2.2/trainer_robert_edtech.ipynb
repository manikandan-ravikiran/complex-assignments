{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "trainer_robert_edtech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6af0c4d120f446a0b18656b522819fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd27428ad70843b9b7b8282afb419767",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7214022b55c34cf987368eb1fa1886e8",
              "IPY_MODEL_75e0fd7d4dde459cb420c81326e37bf8"
            ]
          }
        },
        "cd27428ad70843b9b7b8282afb419767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7214022b55c34cf987368eb1fa1886e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1e1a5bfdbc64e60af0a4c952f0477d9",
            "_dom_classes": [],
            "description": "Evaluating",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 184,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 184,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a114da7339c4f88a68801ca3f43fc46"
          }
        },
        "75e0fd7d4dde459cb420c81326e37bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_536a25b3a15b47e09f9ee77c13ce5bf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 184/184 [00:05&lt;00:00, 31.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab55efb8b7ac4d3e8d6c47123f8b818c"
          }
        },
        "e1e1a5bfdbc64e60af0a4c952f0477d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a114da7339c4f88a68801ca3f43fc46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "536a25b3a15b47e09f9ee77c13ce5bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab55efb8b7ac4d3e8d6c47123f8b818c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f9f7f396742416482767560dbd3df73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e87549eafcb549818accbcaafbb8996c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6bf97a15ef564116a7c7f2b02c81972c",
              "IPY_MODEL_27fb689f1be74901811a6117664f8f7f"
            ]
          }
        },
        "e87549eafcb549818accbcaafbb8996c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bf97a15ef564116a7c7f2b02c81972c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_978bfc31933343e6a8f5f5f8ae94fe51",
            "_dom_classes": [],
            "description": "Evaluating",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 276,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 276,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c96174654c66470a90f84e32a4a3d4eb"
          }
        },
        "27fb689f1be74901811a6117664f8f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b66bf0cb29e84ee19a7899dc7fa3a884",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 276/276 [00:08&lt;00:00, 33.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_553b874423b94475ae81cc24230d90d2"
          }
        },
        "978bfc31933343e6a8f5f5f8ae94fe51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c96174654c66470a90f84e32a4a3d4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b66bf0cb29e84ee19a7899dc7fa3a884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "553b874423b94475ae81cc24230d90d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a05ad2c67304b3fa697568a8e1a1da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2dddd9954984824adfe9069b6ce95ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27820d046d5c4a34a199c3a730ac4ac7",
              "IPY_MODEL_75a796054bd64f38a4340b98c953adfb"
            ]
          }
        },
        "b2dddd9954984824adfe9069b6ce95ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27820d046d5c4a34a199c3a730ac4ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c087e44cfaa345319a9a81e6ff4cf183",
            "_dom_classes": [],
            "description": "Evaluating",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 184,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 184,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee5004f5054a402b9fa3215e27501520"
          }
        },
        "75a796054bd64f38a4340b98c953adfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7679f217ef81420dbe79e0e73aa43eef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 184/184 [00:05&lt;00:00, 32.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae34e59209884adaa908f53988f16f52"
          }
        },
        "c087e44cfaa345319a9a81e6ff4cf183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee5004f5054a402b9fa3215e27501520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7679f217ef81420dbe79e0e73aa43eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae34e59209884adaa908f53988f16f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9f07a047b1d45499eb7a3ca3e225e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b949f4ab265d4b11912080ea0fe59719",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5d0622ed2874b84be80a85e3c2b7308",
              "IPY_MODEL_11c0e68566c6498f9331f8ad2033f0f2"
            ]
          }
        },
        "b949f4ab265d4b11912080ea0fe59719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5d0622ed2874b84be80a85e3c2b7308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3dc2e2d2448841439d114adf21bab3fc",
            "_dom_classes": [],
            "description": "Evaluating",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 276,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 276,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9cf27ab777e42bb86dc3ac64070b710"
          }
        },
        "11c0e68566c6498f9331f8ad2033f0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec40bb64e70143da9368111b009dd4ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 276/276 [00:08&lt;00:00, 32.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_083ff3a372f94cf79e045f8d293440dd"
          }
        },
        "3dc2e2d2448841439d114adf21bab3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9cf27ab777e42bb86dc3ac64070b710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec40bb64e70143da9368111b009dd4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "083ff3a372f94cf79e045f8d293440dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YLoS0hWz-ch",
        "scrolled": true,
        "outputId": "d5139307-90d1-4a0e-d231-35631d2627e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch torchvision pytorch-transformers\n",
        "!pip install scikit-learn pandas tensorflow\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "import csv\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from io import open\n",
        "\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from tqdm import tqdm\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "csv.field_size_limit(2147483647)\n",
        "# writerobj = SummaryWriter()\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "\n",
        "class BinaryProcessor(DataProcessor):\n",
        "    \"\"\"Processor for the binary data sets\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir,data_type=\"dev\"):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, data_type+\".tsv\")), \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"0\",\"1\",\"2\",\"3\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            \n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            try:\n",
        "                text_a = line[3]\n",
        "                label = line[1]\n",
        "            except:\n",
        "                print(line)\n",
        "            #print(text_a,label)\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "        return examples\n",
        "\n",
        "\n",
        "def convert_example_to_feature(example_row, pad_token=0,\n",
        "sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "mask_padding_with_zero=True):\n",
        "    \n",
        "   \n",
        "    \n",
        "    example, label_map, max_seq_length, tokenizer, output_mode, cls_token_at_end, cls_token, sep_token, cls_token_segment_id, pad_on_left, pad_token_segment_id = example_row\n",
        "    #print(example.text_a,\"label-------->\",example.label)\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "        tokens_b = tokenizer.tokenize(example.text_b)\n",
        "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "        # length is less than the specified length.\n",
        "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "    else:\n",
        "        # Account for [CLS] and [SEP] with \"- 2\"\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "    # The convention in BERT is:\n",
        "    # (a) For sequence pairs:\n",
        "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "    #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "    # (b) For single sequences:\n",
        "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "    #  type_ids:   0   0   0   0  0     0   0\n",
        "    #\n",
        "    # Where \"type_ids\" are used to indicate whether this is the first\n",
        "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "    # embedding vector (and position vector). This is not *strictly* necessary\n",
        "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "    # it easier for the model to learn the concept of sequences.\n",
        "    #\n",
        "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "    # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "    # the entire model is fine-tuned.\n",
        "    tokens = tokens_a + [sep_token]\n",
        "    segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "    if tokens_b:\n",
        "        tokens += tokens_b + [sep_token]\n",
        "        segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "    if cls_token_at_end:\n",
        "        tokens = tokens + [cls_token]\n",
        "        segment_ids = segment_ids + [cls_token_segment_id]\n",
        "    else:\n",
        "        tokens = [cls_token] + tokens\n",
        "        segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    padding_length = max_seq_length - len(input_ids)\n",
        "    if pad_on_left:\n",
        "        input_ids = ([pad_token] * padding_length) + input_ids\n",
        "        input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "        segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "    else:\n",
        "        input_ids = input_ids + ([pad_token] * padding_length)\n",
        "        input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "        segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "    \n",
        "    #print(label_map)\n",
        "\n",
        "    if output_mode == \"classification\":\n",
        "        label_id = label_map[example.label]\n",
        "    elif output_mode == \"regression\":\n",
        "        label_id = float(example.label)\n",
        "    else:\n",
        "        raise KeyError(output_mode)\n",
        "\n",
        "    return InputFeatures(input_ids=input_ids,\n",
        "                        input_mask=input_mask,\n",
        "                        segment_ids=segment_ids,\n",
        "                        label_id=label_id)\n",
        "    \n",
        "\n",
        "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
        "                                 tokenizer, output_mode,\n",
        "                                 cls_token_at_end=False, pad_on_left=False,\n",
        "                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
        "                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "                                 cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                                 mask_padding_with_zero=True,\n",
        "                                 process_count=cpu_count() - 2):\n",
        "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "\n",
        "    label_map = {label : i for i, label in enumerate(label_list)}\n",
        "    #print(label_map)\n",
        "\n",
        "    examples = [(example, label_map, max_seq_length, tokenizer, output_mode, cls_token_at_end, cls_token, sep_token, cls_token_segment_id, pad_on_left, pad_token_segment_id) for example in examples]\n",
        "\n",
        "    with Pool(process_count) as p:\n",
        "        features = list(tqdm(p.imap(convert_example_to_feature, examples, chunksize=100), total=len(examples)))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "\n",
        "processors = {\n",
        "    \"binary\": BinaryProcessor\n",
        "}\n",
        "\n",
        "output_modes = {\n",
        "    \"binary\": \"classification\"\n",
        "}\n",
        "\n",
        "GLUE_TASKS_NUM_LABELS = {\n",
        "    \"binary\": 4\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 30.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 36.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 39.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 40.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 43.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 44.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 45.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 46.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 48.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 48.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 48.7MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 48.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 48.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 48.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 48.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 48.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 48.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.11.15)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=a3966ab5b6d2433f9dcd534fd6e8565619a9bc5d3924531d9966e331eb9b9d4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.38 sentencepiece-0.1.85\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (45.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVJDURgfcGf2",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYv4tGNs4Tg8",
        "scrolled": true,
        "outputId": "115a4d2d-7f12-4a6f-d587-6f66b1818215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook\n",
        "import io\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# trainfile = files.upload()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9yhGBXkit1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/My Drive/exp1/train2.tsv\",delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(\"/content/drive/My Drive/exp1/test2.tsv\",delimiter=\"\\t\")\n",
        "dev_df = test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0mmUcSnZi3cv",
        "colab_type": "code",
        "outputId": "1c43b26d-4db3-4caf-cda6-0b77f642e368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "train_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I next attempted to make the agent more genera...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The ability to recognize shapes, and detect th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This agent still can’t solve problems which re...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>For Basic Problem D-06, not only does the shap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In that sense, for buildingunique solution to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>Analysis of Generalization: The rules for CP’s...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>C-06, D-05 uses C-09, Challenge D-01 uses C-12...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>For CP-3 again there is increasing dark pixels...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>For both problems the XOR constraints hold ver...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>Further, investigation on skipped problems rev...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  label\n",
              "0    I next attempted to make the agent more genera...      1\n",
              "1    The ability to recognize shapes, and detect th...      2\n",
              "2    This agent still can’t solve problems which re...      2\n",
              "3    For Basic Problem D-06, not only does the shap...      1\n",
              "4    In that sense, for buildingunique solution to ...      1\n",
              "..                                                 ...    ...\n",
              "271  Analysis of Generalization: The rules for CP’s...      2\n",
              "272  C-06, D-05 uses C-09, Challenge D-01 uses C-12...      1\n",
              "273  For CP-3 again there is increasing dark pixels...      4\n",
              "274  For both problems the XOR constraints hold ver...      4\n",
              "275  Further, investigation on skipped problems rev...      3\n",
              "\n",
              "[276 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hVsnPNzr4XjB",
        "scrolled": true,
        "outputId": "4d5d77c1-4993-44d2-d8f3-3223b53e6d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'id':range(len(train_df)),\n",
        "    'label':train_df[\"label\"].astype(int)-1,\n",
        "    'alpha':['a']*train_df.shape[0],\n",
        "    'text': train_df[\"text\"].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>I next attempted to make the agent more genera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>The ability to recognize shapes, and detect th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>This agent still can’t solve problems which re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>For Basic Problem D-06, not only does the shap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>In that sense, for buildingunique solution to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label alpha                                               text\n",
              "0   0      0     a  I next attempted to make the agent more genera...\n",
              "1   1      1     a  The ability to recognize shapes, and detect th...\n",
              "2   2      1     a  This agent still can’t solve problems which re...\n",
              "3   3      0     a  For Basic Problem D-06, not only does the shap...\n",
              "4   4      0     a  In that sense, for buildingunique solution to ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IkUFgZeh4Xf2",
        "scrolled": true,
        "outputId": "db605652-12a7-4736-e8e5-8066038ff8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "dev_df = pd.DataFrame({\n",
        "    'id':range(len(dev_df)),\n",
        "    'label':dev_df[\"label\"].astype(int)-1,\n",
        "    'alpha':['a']*dev_df.shape[0],\n",
        "    'text': dev_df[\"text\"].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "dev_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>The performance of the agent has increased a l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>This agent still can’t handle problems involvi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>This agent revision has improved performance a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>The Dark Pixel Ratio methodmust be fine-tuned ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Other than that, the root mean square differen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label alpha                                               text\n",
              "0   0      1     a  The performance of the agent has increased a l...\n",
              "1   1      1     a  This agent still can’t handle problems involvi...\n",
              "2   2      1     a  This agent revision has improved performance a...\n",
              "3   3      1     a  The Dark Pixel Ratio methodmust be fine-tuned ...\n",
              "4   4      0     a  Other than that, the root mean square differen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rhQDq4-Gi3dJ",
        "colab_type": "code",
        "outputId": "b8603575-1ae9-4333-a3f8-912ffa9420be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_df = pd.DataFrame({\n",
        "    'id':range(len(test_df)),\n",
        "     'label':test_df[\"label\"].astype(int)-1,\n",
        "    'alpha':['a']*test_df.shape[0],\n",
        "    'text': test_df[\"text\"].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>The performance of the agent has increased a l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>This agent still can’t handle problems involvi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>This agent revision has improved performance a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>The Dark Pixel Ratio methodmust be fine-tuned ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>Other than that, the root mean square differen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label alpha                                               text\n",
              "0   0      1     a  The performance of the agent has increased a l...\n",
              "1   1      1     a  This agent still can’t handle problems involvi...\n",
              "2   2      1     a  This agent revision has improved performance a...\n",
              "3   3      1     a  The Dark Pixel Ratio methodmust be fine-tuned ...\n",
              "4   4      0     a  Other than that, the root mean square differen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pFlvoH234XdO",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "!mkdir data_new_1\n",
        "train_df.to_csv('data_new_1/train.tsv', sep='\\t', index=False, header=False, columns=train_df.columns)\n",
        "dev_df.to_csv('data_new_1/dev.tsv', sep='\\t', index=False, header=False, columns=dev_df.columns)\n",
        "test_df.to_csv('data_new_1/test.tsv', sep='\\t', index=False, header=False, columns=test_df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeXuXWylz7BD",
        "scrolled": true,
        "outputId": "533e3f8d-7243-4b5f-adf0-6a50450df7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!pip install pytorch_transformers\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.17.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.11.15)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.0.38)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.28.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cN3zjpIdi3dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import random\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "\n",
        "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n",
        "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
        "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
        "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "\n",
        "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
        "\n",
        "# from utils import (convert_examples_to_features,\n",
        "#                         output_modes, processors)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F93_pIopz7BG",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "args_bert = {\n",
        "    'data_dir': 'data_new_1/',\n",
        "    'model_type':  'bert',\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'task_name': 'binary',\n",
        "    'output_dir': \"outputs_bert-base-uncased_0.7_taskekant\",\n",
        "    'cache_dir': 'cache/',\n",
        "    'do_train': True,\n",
        "    'do_eval': True,\n",
        "    'fp16': False,\n",
        "    'fp16_opt_level': 'O1',\n",
        "    'max_seq_length': 128,\n",
        "    'output_mode': 'classification',\n",
        "    'train_batch_size': 8,\n",
        "    'eval_batch_size': 1,\n",
        "\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'num_train_epochs': 100,\n",
        "    'weight_decay': 0,\n",
        "    'learning_rate': 1e-10,\n",
        "    'adam_epsilon': 1e-8,\n",
        "    'warmup_steps': 0,\n",
        "    'max_grad_norm': 1.0,\n",
        "\n",
        "    'logging_steps': 50,\n",
        "    'evaluate_during_training': False,\n",
        "    'save_steps': 5000,\n",
        "    'eval_all_checkpoints': True,\n",
        "\n",
        "    'overwrite_output_dir': False,\n",
        "    'reprocess_input_data': False,\n",
        "    'notes': 'Using Yelp Reviews dataset'\n",
        "}\n",
        "\n",
        "args_roberta = {\n",
        "    'data_dir': 'data_new_1/',\n",
        "    'model_type':  'roberta',\n",
        "    'model_name': 'roberta-base',\n",
        "    'task_name': 'binary',\n",
        "    'output_dir': 'outputs_robert-base-0.9_taskbc',\n",
        "    'cache_dir': 'cache_roberta/',\n",
        "    'do_train': True,\n",
        "    'do_eval': True,\n",
        "    'fp16': False,\n",
        "    'fp16_opt_level': 'O1',\n",
        "    'max_seq_length': 128,\n",
        "    'output_mode': 'classification',\n",
        "    'train_batch_size': 16,\n",
        "    'eval_batch_size': 1,\n",
        "\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'num_train_epochs': 10,\n",
        "    'weight_decay': 0,\n",
        "    'learning_rate': 4e-8,\n",
        "    'adam_epsilon': 1e-8,\n",
        "    'warmup_steps': 1000,\n",
        "    'max_grad_norm': 1.0,\n",
        "\n",
        "    'logging_steps': 50,\n",
        "    'evaluate_during_training': False,\n",
        "    'save_steps': 5000,\n",
        "    'eval_all_checkpoints': True,\n",
        "\n",
        "    'overwrite_output_dir': False,\n",
        "    'reprocess_input_data': False,\n",
        "    'notes': 'Using Yelp Reviews dataset'\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzr2RwGLz7BL",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "with open('args_bert.json', 'w') as f:\n",
        "    json.dump(args_bert, f)\n",
        "with open('args_roberta.json', 'w') as f:\n",
        "    json.dump(args_roberta, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ymjmIyOhz7BN",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "if os.path.exists(args_bert['output_dir']) and os.listdir(args_bert['output_dir']) and args_bert['do_train'] and not args_bert['overwrite_output_dir']:\n",
        "    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args_bert['output_dir']))\n",
        "\n",
        "#Create roberta directory\n",
        "if os.path.exists(args_roberta['output_dir']) and os.listdir(args_roberta['output_dir']) and args_roberta['do_train'] and not args_roberta['overwrite_output_dir']:\n",
        "    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args_roberta['output_dir']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LAHYiiLMz7BP",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
        "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
        "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
        "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "}\n",
        "\n",
        "config_class_bert, model_class_bert, tokenizer_class_bert = MODEL_CLASSES[args_bert['model_type']]\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
        "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
        "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
        "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "}\n",
        "\n",
        "#roberta\n",
        "config_class_roberta, model_class_roberta, tokenizer_class_roberta = MODEL_CLASSES[args_roberta['model_type']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qm5AguwFz7BR",
        "scrolled": true,
        "outputId": "64b55ec1-465d-4a57-be39-67d13277be5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "config_bert = config_class_bert.from_pretrained(args_bert['model_name'], num_labels=4, finetuning_task=args_bert['task_name'])#, output_hidden_states=True)\n",
        "tokenizer_bert = tokenizer_class_bert.from_pretrained(args_bert['model_name'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpyzvhpyj_\n",
            "100%|██████████| 361/361 [00:00<00:00, 83364.19B/s]\n",
            "INFO:pytorch_transformers.file_utils:copying /tmp/tmpyzvhpyj_ to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpyzvhpyj_\n",
            "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "INFO:pytorch_transformers.modeling_utils:Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"binary\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 4,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp8gc6sgnu\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 418525.40B/s]\n",
            "INFO:pytorch_transformers.file_utils:copying /tmp/tmp8gc6sgnu to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmp8gc6sgnu\n",
            "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IGZHNvKAz7BU",
        "scrolled": true,
        "outputId": "055e4747-ff0e-4508-95f1-3ba865289601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "model_bert = model_class_bert.from_pretrained(args_bert['model_name'],num_labels=4)\n",
        "# for name, param in model_bert.named_parameters():\n",
        "# \tif 'classifier' not in name: # classifier layer\n",
        "# \t\tparam.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "INFO:pytorch_transformers.modeling_utils:Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 4,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpuuttd_ka\n",
            " 36%|███▋      | 160195584/440473133 [00:14<00:20, 14013356.01B/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xyxKpk_6z7BW",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "\n",
        "model_bert.to(device);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bsPmRyGE8GnR",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1b3mlOg-yk",
        "colab_type": "code",
        "outputId": "e3568fa5-eb49-4b28-90fe-c0103a77083c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# # model_bert\n",
        "\n",
        "# #Roberta\n",
        "# config_roberta = config_class_roberta.from_pretrained(args_roberta['model_name'], num_labels=4, finetuning_task=args_roberta['task_name'])\n",
        "# tokenizer_roberta = tokenizer_class_roberta.from_pretrained(args_roberta['model_name'])\n",
        "# model_roberta= model_class_roberta.from_pretrained(args_roberta['model_name'],num_labels=4)\n",
        "# model_roberta.to(device);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /tmp/tmpnub_r11_\n",
            "100%|██████████| 524/524 [00:00<00:00, 122776.12B/s]\n",
            "INFO:pytorch_transformers.file_utils:copying /tmp/tmpnub_r11_ to cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
            "INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
            "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpnub_r11_\n",
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /tmp/tmpwqb5wiv8\n",
            "100%|██████████| 898823/898823 [00:01<00:00, 700740.49B/s]\n",
            "INFO:pytorch_transformers.file_utils:copying /tmp/tmpwqb5wiv8 to cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpwqb5wiv8\n",
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /tmp/tmplzn8ejbu\n",
            "100%|██████████| 456318/456318 [00:01<00:00, 422584.80B/s]\n",
            "INFO:pytorch_transformers.file_utils:copying /tmp/tmplzn8ejbu to cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmplzn8ejbu\n",
            "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpus8mgjwx\n",
            "100%|██████████| 501200538/501200538 [00:46<00:00, 10778062.33B/s]\n",
            "INFO:pytorch_transformers.file_utils:copying /tmp/tmpus8mgjwx to cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpus8mgjwx\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe4P94Bfz7Ba",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "task = args_bert['task_name']\n",
        "\n",
        "processor = processors[task]()\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xqr_fwM3z7Bd",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "def load_and_cache_examples(task, tokenizer,argus, evaluate=False,undersample_scale_factor=1,data_type=\"dev\"):\n",
        "    args=argus.copy()\n",
        "    processor = processors[task]()\n",
        "    output_mode = args['output_mode']\n",
        "    \n",
        "    mode = 'dev' if evaluate else 'train'\n",
        "    cached_features_file = os.path.join(args['data_dir'], \"cached_\"+str(mode)+\"_\"+str(args['model_name'])+\"_\"+str(args['max_seq_length'])+\"_\"+str(task))\n",
        "    \n",
        "    if os.path.exists(cached_features_file) and not args['reprocess_input_data'] and False:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "               \n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
        "        label_list = processor.get_labels()\n",
        "        examples = processor.get_dev_examples(args['data_dir'],data_type) if evaluate else processor.get_train_examples(args['data_dir'])\n",
        "#         print(len(examples))\n",
        "        examples  = [example for example in examples]\n",
        "        #print((examples))\n",
        "        \n",
        "        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
        "            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
        "            cls_token=tokenizer.cls_token,\n",
        "            sep_token=tokenizer.sep_token,\n",
        "            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
        "            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
        "            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0,\n",
        "            process_count=2)\n",
        "        \n",
        "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "        torch.save(features, cached_features_file)\n",
        "        \n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "    if output_mode == \"classification\":\n",
        "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
        "    elif output_mode == \"regression\":\n",
        "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
        "\n",
        "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oCul6vvCz7Bg",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "def train(train_dataset, model, tokenizer,argus):\n",
        "    global writerobj\n",
        "    args=argus.copy()\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
        "    \n",
        "    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
        "    \n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
        "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args['warmup_steps'], t_total=t_total)\n",
        "    \n",
        "    if args['fp16']:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
        "        \n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
        "    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
        "    \n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            model.train()\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
        "                      'labels':         batch[3]}\n",
        "            outputs = model(**inputs)\n",
        "            #print(model.bert(**inputs).shape)\n",
        "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
        "            print(\"\\r%f\" % loss, end='')\n",
        "            #writerobj.add_scalar('Loss/train', float(loss), global_step)\n",
        "            \n",
        "\n",
        "            if args['gradient_accumulation_steps'] > 1:\n",
        "                loss = loss / args['gradient_accumulation_steps']\n",
        "                \n",
        "               \n",
        "                \n",
        " \n",
        "            if args['fp16']:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
        "                \n",
        "            else:\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
        "            \n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
        "                \n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n",
        "                    # Log metrics\n",
        "                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(model, tokenizer)\n",
        "                        \n",
        "\n",
        "                    logging_loss = tr_loss\n",
        "                    \n",
        "\n",
        "                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args['output_dir'], 'checkpoint')\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "            \n",
        "\n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tUvkEBZUz7Bk",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix, classification_report\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def get_mismatched(labels, preds):\n",
        "    mismatched = labels != preds\n",
        "    examples = processor.get_dev_examples(args_bert['data_dir'])\n",
        "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
        "    \n",
        "    return wrong\n",
        "\n",
        "def get_eval_report(labels, preds):\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    print(classification_report(labels, preds))\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "    print(classification_report(labels, preds))\n",
        "   \n",
        "    return {\n",
        "        \"mcc\": mcc,\n",
        "        \"tp\": tp,\n",
        "        \"tn\": tn,\n",
        "        \"fp\": fp,\n",
        "        \"fn\": fn\n",
        "    }, get_mismatched(labels, preds)\n",
        "\n",
        "def compute_metrics(task_name, preds, labels):\n",
        "    assert len(preds) == len(labels)\n",
        "    return get_eval_report(labels, preds)\n",
        "\n",
        "def evaluate(model, argus, tokenizer, prefix=\"\",datatype=\"dev\"):\n",
        "    \n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    args=argus.copy()\n",
        "    eval_output_dir = args['output_dir']\n",
        "\n",
        "    results = {}\n",
        "    EVAL_TASK = args['task_name']\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, args, undersample_scale_factor=1, evaluate=True,data_type=datatype)\n",
        "    if not os.path.exists(eval_output_dir):\n",
        "        os.makedirs(eval_output_dir)\n",
        "\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    #print(len(eval_dataset))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    probs=None\n",
        "    net_input=None\n",
        "    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
        "                      'labels':         batch[3]}\n",
        "            outputs = model(**inputs)\n",
        "            feature=model.bert(inputs[\"input_ids\"],inputs[\"token_type_ids\"],inputs[\"attention_mask\"])[1].cpu().numpy()\n",
        "            print(feature.shape)\n",
        "            tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        \n",
        "        if preds is None:\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            probs= preds.copy()\n",
        "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
        "            net_input=inputs['input_ids'].detach().cpu().numpy()\n",
        "        else:\n",
        "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
        "            probs=np.append(probs,logits.detach().cpu().numpy(), axis=0)\n",
        "            net_input=np.append(net_input,inputs['input_ids'].detach().cpu().numpy(),axis=0)\n",
        "            \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    if args['output_mode'] == \"classification\":\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "    elif args['output_mode'] == \"regression\":\n",
        "        preds = np.squeeze(preds)\n",
        "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
        "    results.update(result)\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return results, wrong,probs,preds,out_label_ids,net_input\n",
        "\n",
        "\n",
        "def extract_features(model, argus, tokenizer, prefix=\"\",datatype=\"dev\"):\n",
        "    \n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    args=argus.copy()\n",
        "    eval_output_dir = args['output_dir']\n",
        "\n",
        "    results = {}\n",
        "    EVAL_TASK = args['task_name']\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, args, undersample_scale_factor=1, evaluate=True,data_type=datatype)\n",
        "    if not os.path.exists(eval_output_dir):\n",
        "        os.makedirs(eval_output_dir)\n",
        "\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    #print(len(eval_dataset))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "\n",
        "\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    probs=None\n",
        "    net_input=None\n",
        "    \n",
        "    #save data\n",
        "    all_features=[]\n",
        "    all_sentences=[]\n",
        "    all_labels=[]\n",
        "\n",
        "    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # print(tokenizer.decode(batch[0])#.decode)\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
        "                      'labels':         batch[3]}\n",
        "            outputs = model(**inputs)\n",
        "            feature=model.bert(inputs[\"input_ids\"],inputs[\"token_type_ids\"],inputs[\"attention_mask\"])[1].cpu().numpy()\n",
        "            \n",
        "            all_features.append(feature[0])\n",
        "            all_sentences.append(feature)\n",
        "            all_labels.append(batch[3].cpu().numpy())\n",
        "\n",
        "    return all_features,all_sentences,all_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlaeXY9sz7Bm",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# #Train_bert\n",
        "# if args_bert['do_train']:\n",
        "#     print(\"Training Bert!!\")\n",
        "#     train_dataset = load_and_cache_examples(task, tokenizer_bert,args_bert,undersample_scale_factor=1)\n",
        "#     #print(train_dataset)\n",
        "#     global_step, tr_loss = train(train_dataset, model_bert, tokenizer_bert,args_bert)\n",
        "#     logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyeG-GCnEcLF",
        "colab_type": "code",
        "outputId": "1c41b3bb-0797-4167-d584-6d571bca8a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# #Train Roberta\n",
        "# if args_roberta['do_train']:\n",
        "#     print(\"Training RoBert!!\")\n",
        "#     train_dataset = load_and_cache_examples(task, tokenizer_roberta,args_roberta,undersample_scale_factor=1)\n",
        "#     #print(train_dataset)\n",
        "#     global_step, tr_loss = train(train_dataset, model_roberta, tokenizer_roberta,args_roberta)\n",
        "#     logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "if True:\n",
        "    if not os.path.exists(args_roberta['output_dir']):\n",
        "            os.makedirs(args_roberta['output_dir'])\n",
        "    logger.info(\"Saving model checkpoint to %s\", args_roberta['output_dir'])\n",
        "    \n",
        "    model_to_save = model_roberta.module if hasattr(model_roberta, 'module') else model_roberta  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(args_roberta['output_dir'])\n",
        "    tokenizer_roberta.save_pretrained(args_roberta['output_dir'])\n",
        "    torch.save(args_roberta, os.path.join(args_roberta['output_dir'], 'training_args.bin'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Saving model checkpoint to outputs_robert-base-0.9_taskbc\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1On6YjIULf7v",
        "scrolled": true,
        "outputId": "b3f72ddd-08a3-48d0-ab50-5394b46916a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Save bert\n",
        "if args_bert['do_train']:\n",
        "    if not os.path.exists(args_bert['output_dir']):\n",
        "            os.makedirs(args_bert['output_dir'])\n",
        "    logger.info(\"Saving model checkpoint to %s\", args_bert['output_dir'])\n",
        "    \n",
        "    model_to_save = model_bert.module if hasattr(model_bert, 'module') else model_bert  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(args_bert['output_dir'])\n",
        "    tokenizer_bert.save_pretrained(args_bert['output_dir'])\n",
        "    torch.save(args_bert, os.path.join(args_bert['output_dir'], 'training_args.bin'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Saving model checkpoint to outputs_bert-base-uncased_0.7_taskekant\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfKV6fwii3ev",
        "colab_type": "text"
      },
      "source": [
        "# Get test set predictions and probs for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nlIp1xZai3ex",
        "colab_type": "code",
        "outputId": "691cdff9-c154-401a-ea0d-3d3b2888807c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "6af0c4d120f446a0b18656b522819fd4",
            "cd27428ad70843b9b7b8282afb419767",
            "7214022b55c34cf987368eb1fa1886e8",
            "75e0fd7d4dde459cb420c81326e37bf8",
            "e1e1a5bfdbc64e60af0a4c952f0477d9",
            "5a114da7339c4f88a68801ca3f43fc46",
            "536a25b3a15b47e09f9ee77c13ce5bf3",
            "ab55efb8b7ac4d3e8d6c47123f8b818c",
            "1f9f7f396742416482767560dbd3df73",
            "e87549eafcb549818accbcaafbb8996c",
            "6bf97a15ef564116a7c7f2b02c81972c",
            "27fb689f1be74901811a6117664f8f7f",
            "978bfc31933343e6a8f5f5f8ae94fe51",
            "c96174654c66470a90f84e32a4a3d4eb",
            "b66bf0cb29e84ee19a7899dc7fa3a884",
            "553b874423b94475ae81cc24230d90d2"
          ]
        }
      },
      "source": [
        "results = {}\n",
        "if args_bert['do_eval']:\n",
        "    checkpoints = [args_bert['output_dir']]\n",
        "    if args_bert['eval_all_checkpoints']:\n",
        "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args_bert['output_dir']+ '/**/' + WEIGHTS_NAME, recursive=True)))\n",
        "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "    for checkpoint in checkpoints:\n",
        "        print(checkpoint)\n",
        "        if True:\n",
        "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
        "            model = model_class_bert.from_pretrained(checkpoint)\n",
        "            model.to(device)\n",
        "            xtest, sentence,ytest= extract_features(model, args_bert,tokenizer_bert, prefix=global_step,datatype=\"test\")\n",
        "\n",
        "\n",
        "results = {}\n",
        "if args_bert['do_eval']:\n",
        "    checkpoints = [args_bert['output_dir']]\n",
        "    if args_bert['eval_all_checkpoints']:\n",
        "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args_bert['output_dir']+ '/**/' + WEIGHTS_NAME, recursive=True)))\n",
        "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "    for checkpoint in checkpoints:\n",
        "        print(checkpoint)\n",
        "        if True:\n",
        "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
        "            model = model_class_bert.from_pretrained(checkpoint)\n",
        "            model.to(device)\n",
        "            xtrain, sentence,ytrain= extract_features(model, args_bert,tokenizer_bert, prefix=global_step,datatype=\"train\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Evaluate the following checkpoints: ['outputs_bert-base-uncased_0.7_taskekant']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outputs_bert-base-uncased_0.7_taskekant\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Creating features from dataset file at data_new_1/\n",
            "100%|██████████| 184/184 [00:00<00:00, 1735.36it/s]\n",
            "INFO:__main__:Saving features into cached file data_new_1/cached_dev_bert-base-uncased_128_binary\n",
            "INFO:__main__:***** Running evaluation  *****\n",
            "INFO:__main__:  Num examples = 184\n",
            "INFO:__main__:  Batch size = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6af0c4d120f446a0b18656b522819fd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Evaluating', max=184, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Evaluate the following checkpoints: ['outputs_bert-base-uncased_0.7_taskekant']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "outputs_bert-base-uncased_0.7_taskekant\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Creating features from dataset file at data_new_1/\n",
            "100%|██████████| 276/276 [00:00<00:00, 1406.37it/s]\n",
            "INFO:__main__:Saving features into cached file data_new_1/cached_dev_bert-base-uncased_128_binary\n",
            "INFO:__main__:***** Running evaluation  *****\n",
            "INFO:__main__:  Num examples = 276\n",
            "INFO:__main__:  Batch size = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f9f7f396742416482767560dbd3df73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Evaluating', max=276, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z_EIFKe0KsN",
        "colab_type": "code",
        "outputId": "08fd3a3c-1a52-463d-c08e-0ececc84fc05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5]\n",
        "        }\n",
        "\n",
        "ytrain=np.array(ytrain).ravel()\n",
        "ytest=np.array(ytest).ravel()\n",
        "\n",
        "\n",
        "class_weights = list(class_weight.compute_class_weight('balanced',np.unique(ytrain),np.array(ytrain)))\n",
        "w_array = np.ones(ytrain.shape[0], dtype = 'float')\n",
        "\n",
        "for i, val in enumerate(ytrain):\n",
        "    w_array[i] = class_weights[val-1]\n",
        "\n",
        "clf= SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=20, random_state=42,class_weight=\"balanced\",warm_start=True)#XGBClassifier()\n",
        "clf2=XGBClassifier(sample_weight=w_array)\n",
        "\n",
        "clf.fit(np.array(xtrain),np.array(ytrain))\n",
        "clf2.fit(np.array(xtrain),np.array(ytrain))\n",
        "\n",
        "ypred=clf.predict(xtest)\n",
        "ypred2=clf2.predict(xtest)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"SGD\")\n",
        "print(classification_report(np.array(ytest).ravel(),ypred))\n",
        "\n",
        "\n",
        "print(\"XGB\")\n",
        "print(classification_report(np.array(ytest).ravel(),ypred2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SGD\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        56\n",
            "           1       0.38      0.03      0.06        90\n",
            "           2       0.09      0.93      0.16        15\n",
            "           3       0.21      0.17      0.19        23\n",
            "\n",
            "    accuracy                           0.11       184\n",
            "   macro avg       0.17      0.29      0.10       184\n",
            "weighted avg       0.22      0.11      0.07       184\n",
            "\n",
            "XGB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.34      0.44        56\n",
            "           1       0.57      0.88      0.69        90\n",
            "           2       0.33      0.07      0.11        15\n",
            "           3       0.25      0.13      0.17        23\n",
            "\n",
            "    accuracy                           0.55       184\n",
            "   macro avg       0.44      0.35      0.35       184\n",
            "weighted avg       0.52      0.55      0.50       184\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c17UuvIA42Wx",
        "colab_type": "code",
        "outputId": "6a9381b3-e74b-45b1-b1ad-6f5e6c0648a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a05ad2c67304b3fa697568a8e1a1da6",
            "b2dddd9954984824adfe9069b6ce95ea",
            "27820d046d5c4a34a199c3a730ac4ac7",
            "75a796054bd64f38a4340b98c953adfb",
            "c087e44cfaa345319a9a81e6ff4cf183",
            "ee5004f5054a402b9fa3215e27501520",
            "7679f217ef81420dbe79e0e73aa43eef",
            "ae34e59209884adaa908f53988f16f52",
            "b9f07a047b1d45499eb7a3ca3e225e8e",
            "b949f4ab265d4b11912080ea0fe59719",
            "a5d0622ed2874b84be80a85e3c2b7308",
            "11c0e68566c6498f9331f8ad2033f0f2",
            "3dc2e2d2448841439d114adf21bab3fc",
            "a9cf27ab777e42bb86dc3ac64070b710",
            "ec40bb64e70143da9368111b009dd4ce",
            "083ff3a372f94cf79e045f8d293440dd"
          ]
        }
      },
      "source": [
        "results = {}\n",
        "if args_roberta['do_eval']:\n",
        "    checkpoints = [args_roberta['output_dir']]\n",
        "    if args_roberta['eval_all_checkpoints']:\n",
        "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args_roberta['output_dir']+ '/**/' + WEIGHTS_NAME, recursive=True)))\n",
        "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "    for checkpoint in checkpoints:\n",
        "        print(checkpoint)\n",
        "        if True:\n",
        "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
        "            model = model_class_bert.from_pretrained(checkpoint)\n",
        "            model.to(device)\n",
        "            xtest, sentence,ytest= extract_features(model, args_roberta,tokenizer_roberta, prefix=global_step,datatype=\"test\")\n",
        "\n",
        "results = {}\n",
        "if args_roberta['do_eval']:\n",
        "    checkpoints = [args_roberta['output_dir']]\n",
        "    if args_roberta['eval_all_checkpoints']:\n",
        "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args_roberta['output_dir']+ '/**/' + WEIGHTS_NAME, recursive=True)))\n",
        "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "    for checkpoint in checkpoints:\n",
        "        print(checkpoint)\n",
        "        if True:\n",
        "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
        "            model = model_class_bert.from_pretrained(checkpoint)\n",
        "            model.to(device)\n",
        "            xtrain, sentence,ytrain= extract_features(model, args_roberta,tokenizer_roberta, prefix=global_step,datatype=\"train\")\n",
        "        \n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5]\n",
        "        }\n",
        "\n",
        "ytrain=np.array(ytrain).ravel()\n",
        "ytest=np.array(ytest).ravel()\n",
        "\n",
        "\n",
        "print(ytrain)\n",
        "\n",
        "class_weights = list(class_weight.compute_class_weight('balanced',np.unique(ytrain),np.array(ytrain)))\n",
        "w_array = np.ones(ytrain.shape[0], dtype = 'float')\n",
        "\n",
        "for i, val in enumerate(ytrain):\n",
        "    w_array[i] = class_weights[val-1]\n",
        "\n",
        "clf= SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=20, random_state=42,class_weight=\"balanced\",warm_start=False)#XGBClassifier()\n",
        "clf2=XGBClassifier()\n",
        "\n",
        "clf.fit(np.array(xtrain),np.array(ytrain))\n",
        "clf2.fit(np.array(xtrain),np.array(ytrain))#,sample_weight=w_array)\n",
        "\n",
        "ypred=clf.predict(xtest)\n",
        "ypred2=clf2.predict(xtest)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"SGD\")\n",
        "print(classification_report(np.array(ytest).ravel(),ypred))\n",
        "\n",
        "\n",
        "print(\"XGB\")\n",
        "print(classification_report(np.array(ytest).ravel(),ypred2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Evaluate the following checkpoints: ['outputs_robert-base-0.9_taskbc']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outputs_robert-base-0.9_taskbc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Creating features from dataset file at data_new_1/\n",
            "100%|██████████| 184/184 [00:00<00:00, 514.05it/s]\n",
            "INFO:__main__:Saving features into cached file data_new_1/cached_dev_roberta-base_128_binary\n",
            "INFO:__main__:***** Running evaluation  *****\n",
            "INFO:__main__:  Num examples = 184\n",
            "INFO:__main__:  Batch size = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a05ad2c67304b3fa697568a8e1a1da6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Evaluating', max=184, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Evaluate the following checkpoints: ['outputs_robert-base-0.9_taskbc']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "outputs_robert-base-0.9_taskbc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Creating features from dataset file at data_new_1/\n",
            "100%|██████████| 276/276 [00:00<00:00, 609.90it/s]\n",
            "INFO:__main__:Saving features into cached file data_new_1/cached_dev_roberta-base_128_binary\n",
            "INFO:__main__:***** Running evaluation  *****\n",
            "INFO:__main__:  Num examples = 276\n",
            "INFO:__main__:  Batch size = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9f07a047b1d45499eb7a3ca3e225e8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Evaluating', max=276, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[0 1 1 0 0 2 1 0 1 3 1 3 3 1 1 1 0 3 0 0 1 0 2 2 0 1 3 0 3 1 0 1 1 1 0 0 1\n",
            " 1 1 3 0 3 3 1 0 1 1 1 1 1 3 0 1 1 1 1 3 1 1 0 1 1 1 1 1 3 1 1 3 0 1 0 1 1\n",
            " 1 3 1 1 1 1 1 2 2 1 0 1 2 0 0 0 0 2 1 0 1 0 1 1 2 3 0 1 1 0 1 1 1 0 3 0 0\n",
            " 1 3 3 0 0 2 3 1 3 2 0 3 0 1 1 2 0 1 1 0 0 1 1 2 1 1 1 1 0 1 1 3 1 3 1 2 1\n",
            " 0 0 1 1 1 2 1 1 1 1 1 1 1 0 1 1 0 0 1 3 0 1 1 1 1 3 1 3 0 1 0 1 0 1 0 3 1\n",
            " 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 0 1 3 1 2 1 1 1 0 2 0 0 1 3 1 1 1 3 1 1 3 0\n",
            " 0 3 3 1 0 1 1 0 2 2 1 1 3 3 1 3 1 1 0 1 1 0 0 0 0 1 1 0 3 0 1 1 0 0 1 1 3\n",
            " 3 1 0 1 3 1 0 3 0 1 0 1 1 0 3 3 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SGD\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        56\n",
            "           1       0.00      0.00      0.00        90\n",
            "           2       0.07      0.13      0.09        15\n",
            "           3       0.12      0.78      0.20        23\n",
            "\n",
            "    accuracy                           0.11       184\n",
            "   macro avg       0.05      0.23      0.07       184\n",
            "weighted avg       0.02      0.11      0.03       184\n",
            "\n",
            "XGB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.04      0.06        56\n",
            "           1       0.50      0.16      0.24        90\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.12      0.78      0.21        23\n",
            "\n",
            "    accuracy                           0.18       184\n",
            "   macro avg       0.20      0.24      0.13       184\n",
            "weighted avg       0.32      0.18      0.16       184\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7qGnbELGkLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}