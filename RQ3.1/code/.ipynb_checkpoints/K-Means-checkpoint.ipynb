{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#K-Means import\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data,labels=None):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=None)))\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "traindata=pd.read_csv(\"../data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "for rstate in [16]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "    cfmatrix=confusion_matrix(np.array(Y_test)-1,ypred)\n",
    "    print(cfmatrix)\n",
    "    \n",
    "\n",
    "#     print(\"Random Initialization\")\n",
    "#     ypred=km1_random.predict(X_test)\n",
    "#     print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "\n",
    "#     print(\"PCA Components Initialization\")\n",
    "#     ypred=km1_pca.predict(X_test)\n",
    "#     print(classification_report(np.array(Y_test)-1,ypred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cfmatrix, index=[\"stage 1\", \"stage 2\", \"stage 3\", \"stagte 4\"], columns=[\"stage 1\", \"stage 2\", \"stage 3\", \"stagte 4\"])\n",
    "\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.collections import QuadMesh\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "def get_new_fig(fn, figsize=[9,9]):\n",
    "    \"\"\" Init graphics \"\"\"\n",
    "    fig1 = plt.figure(fn, figsize)\n",
    "    ax1 = fig1.gca()   #Get Current Axis\n",
    "    ax1.cla() # clear existing plot\n",
    "    return fig1, ax1\n",
    "#\n",
    "\n",
    "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
    "    \"\"\"\n",
    "      config cell text and colors\n",
    "      and return text elements to add and to dell\n",
    "      @TODO: use fmt\n",
    "    \"\"\"\n",
    "    text_add = []; text_del = [];\n",
    "    cell_val = array_df[lin][col]\n",
    "    tot_all = array_df[-1][-1]\n",
    "    per = (float(cell_val) / tot_all) * 100\n",
    "    curr_column = array_df[:,col]\n",
    "    ccl = len(curr_column)\n",
    "\n",
    "    #last line  and/or last column\n",
    "    if(col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "        #tots and percents\n",
    "        if(cell_val != 0):\n",
    "            if(col == ccl - 1) and (lin == ccl - 1):\n",
    "                tot_rig = 0\n",
    "                for i in range(array_df.shape[0] - 1):\n",
    "                    tot_rig += array_df[i][i]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(col == ccl - 1):\n",
    "                tot_rig = array_df[lin][lin]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(lin == ccl - 1):\n",
    "                tot_rig = array_df[col][col]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            per_err = 100 - per_ok\n",
    "        else:\n",
    "            per_ok = per_err = 0\n",
    "\n",
    "        per_ok_s = ['%.2f%%'%(per_ok), '100%'] [per_ok == 100]\n",
    "\n",
    "        #text to DEL\n",
    "        text_del.append(oText)\n",
    "\n",
    "        #text to ADD\n",
    "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
    "        text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum', fontproperties=font_prop)\n",
    "        lis_txt = ['%d'%(cell_val), per_ok_s, '%.2f%%'%(per_err)]\n",
    "        lis_kwa = [text_kwargs]\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'g'; lis_kwa.append(dic);\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'r'; lis_kwa.append(dic);\n",
    "        lis_pos = [(oText._x, oText._y-0.3), (oText._x, oText._y), (oText._x, oText._y+0.3)]\n",
    "        for i in range(len(lis_txt)):\n",
    "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
    "            #print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)\n",
    "            text_add.append(newText)\n",
    "        #print '\\n'\n",
    "\n",
    "        #set background color for sum cells (last line and last column)\n",
    "        carr = [0.27, 0.30, 0.27, 1.0]\n",
    "        if(col == ccl - 1) and (lin == ccl - 1):\n",
    "            carr = [0.17, 0.20, 0.17, 1.0]\n",
    "        facecolors[posi] = carr\n",
    "\n",
    "    else:\n",
    "        if(per > 0):\n",
    "            txt = '%s\\n%.2f%%' %(cell_val, per)\n",
    "        else:\n",
    "            if(show_null_values == 0):\n",
    "                txt = ''\n",
    "            elif(show_null_values == 1):\n",
    "                txt = '0'\n",
    "            else:\n",
    "                txt = '0\\n0.0%'\n",
    "        oText.set_text(txt)\n",
    "\n",
    "        #main diagonal\n",
    "        if(col == lin):\n",
    "            #set color of the textin the diagonal to white\n",
    "            oText.set_color('w')\n",
    "            # set background color in the diagonal to blue\n",
    "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "        else:\n",
    "            oText.set_color('r')\n",
    "\n",
    "    return text_add, text_del\n",
    "#\n",
    "\n",
    "def insert_totals(df_cm):\n",
    "    \"\"\" insert total column and line (the last ones) \"\"\"\n",
    "    sum_col = []\n",
    "    for c in df_cm.columns:\n",
    "        sum_col.append( df_cm[c].sum() )\n",
    "    sum_lin = []\n",
    "    for item_line in df_cm.iterrows():\n",
    "        sum_lin.append( item_line[1].sum() )\n",
    "    df_cm['sum_lin'] = sum_lin\n",
    "    sum_col.append(np.sum(sum_lin))\n",
    "    df_cm.loc['sum_col'] = sum_col\n",
    "    #print ('\\ndf_cm:\\n', df_cm, '\\n\\b\\n')\n",
    "#\n",
    "\n",
    "def pretty_plot_confusion_matrix(df_cm, annot=True, cmap=\"Oranges\", fmt='.2f', fz=11,\n",
    "      lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='y'):\n",
    "    \"\"\"\n",
    "      print conf matrix with default layout (like matlab)\n",
    "      params:\n",
    "        df_cm          dataframe (pandas) without totals\n",
    "        annot          print text in each cell\n",
    "        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "        fz             fontsize\n",
    "        lw             linewidth\n",
    "        pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                        'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                        'lin' or 'y': show predicted values in lines   (y axis)\n",
    "    \"\"\"\n",
    "    if(pred_val_axis in ('col', 'x')):\n",
    "        xlbl = 'Predicted'\n",
    "        ylbl = 'Actual'\n",
    "    else:\n",
    "        xlbl = 'Actual'\n",
    "        ylbl = 'Predicted'\n",
    "        df_cm = df_cm.T\n",
    "\n",
    "    # create \"Total\" column\n",
    "    insert_totals(df_cm)\n",
    "\n",
    "    #this is for print allways in the same window\n",
    "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
    "\n",
    "    #thanks for seaborn\n",
    "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw, ax=ax1,\n",
    "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
    "\n",
    "    #set ticklabels rotation\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, fontsize = 10)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 10)\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    #face colors list\n",
    "    quadmesh = ax.findobj(QuadMesh)[0]\n",
    "    facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "    #iter in text elements\n",
    "    array_df = np.array( df_cm.to_records(index=False).tolist() )\n",
    "    text_add = []; text_del = [];\n",
    "    posi = -1 #from left to right, bottom to top.\n",
    "    for t in ax.collections[0].axes.texts: #ax.texts:\n",
    "        pos = np.array( t.get_position()) - [0.5,0.5]\n",
    "        lin = int(pos[1]); col = int(pos[0]);\n",
    "        posi += 1\n",
    "        #print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))\n",
    "\n",
    "        #set text\n",
    "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)\n",
    "\n",
    "        text_add.extend(txt_res[0])\n",
    "        text_del.extend(txt_res[1])\n",
    "\n",
    "    #remove the old ones\n",
    "    for item in text_del:\n",
    "        item.remove()\n",
    "    #append the new ones\n",
    "    for item in text_add:\n",
    "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
    "\n",
    "    #titles and legends\n",
    "    ax.set_title('Confusion matrix')\n",
    "    ax.set_xlabel(xlbl)\n",
    "    ax.set_ylabel(ylbl)\n",
    "    plt.tight_layout()  #set layout slim\n",
    "    plt.show()\n",
    "#\n",
    "\n",
    "def plot_confusion_matrix_from_data(y_test, predictions, columns=None, annot=True, cmap=\"Oranges\",\n",
    "      fmt='.2f', fz=11, lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='lin'):\n",
    "    \"\"\"\n",
    "        plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
    "        whitout a confusion matrix yet\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    #data\n",
    "    if(not columns):\n",
    "        #labels axis integer:\n",
    "        ##columns = range(1, len(np.unique(y_test))+1)\n",
    "        #labels axis string:\n",
    "        from string import ascii_uppercase\n",
    "        columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(y_test))]]\n",
    "\n",
    "    confm = confusion_matrix(y_test, predictions)\n",
    "    cmap = 'Oranges';\n",
    "    fz = 11;\n",
    "    figsize=[9,9];\n",
    "    show_null_values = 2\n",
    "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
    "    pretty_plot_confusion_matrix(df_cm, fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values, pred_val_axis=pred_val_axis)\n",
    "#\n",
    "\n",
    "plot_confusion_matrix_from_data(np.array(Y_test)-1,ypred,columns=[\"Overview\",\"Congitive Connection\",\"Relation to KBAI Class\",\"Agent Reasoning\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MeansFold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "# Do K-Means\n",
    "for rstate in [2]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test)-1,ypred,digits=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Autoclustering with Elbow Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOld -1\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"../data/tsv/test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"../data/tsv/train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True))])\n",
    "clf.fit(X_train)\n",
    "\n",
    "\n",
    "X_train=(clf.transform(X_train)).toarray()\n",
    "X_test=clf.transform(X_test)\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)-1\n",
    "# print(labels)\n",
    "\n",
    "\n",
    "distortions = []\n",
    "for i in range(1, 100):\n",
    "    km = KMeans(init='k-means++', n_clusters=i, n_init=10,random_state=rstate)\n",
    "    km.fit(data)\n",
    "    distortions.append(km.inertia_)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(1, 100), distortions, marker='-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means with language model representations from RQ 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#change modelfolder path to get results across different embeddings\n",
    "\n",
    "modelfolder=\"../../RQ2.2/data/bert/fold1/\"\n",
    "\n",
    "X_train= pickle.load(open(modelfolder+'xtrain.pkl', 'rb'))\n",
    "Y_train= pickle.load(open(modelfolder+'ytrain.pkl', 'rb'))\n",
    "X_test= pickle.load(open(modelfolder+'xtest.pkl', 'rb'))\n",
    "Y_test= pickle.load(open(modelfolder+'ytest.pkl', 'rb'))\n",
    "\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "for rstate in [23]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "modelfolder=\"../../RQ2.2/data/bert/fold1/\"\n",
    "\n",
    "X_train= pickle.load(open(modelfolder+'xtrain.pkl', 'rb'))\n",
    "Y_train= pickle.load(open(modelfolder+'ytrain.pkl', 'rb'))\n",
    "X_test= pickle.load(open(modelfolder+'xtest.pkl', 'rb'))\n",
    "Y_test= pickle.load(open(modelfolder+'ytest.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "data=X_train\n",
    "labels=np.array(Y_train)\n",
    "# print(labels)\n",
    "\n",
    "# Do K-Means\n",
    "for rstate in [1]:\n",
    "    \n",
    "    print(\"Random State\", rstate)\n",
    "    \n",
    "    print(82 * '_')\n",
    "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    km1_km=bench_k_means(KMeans(init='k-means++', n_clusters=4, n_init=10,random_state=rstate), name=\"k-means++\", data=data,labels=labels)\n",
    "\n",
    "    km1_random=bench_k_means(KMeans(init='random', n_clusters=4, n_init=10,random_state=rstate), name=\"random\", data=data,labels=labels)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=4).fit(data) \n",
    "    km1_pca=bench_k_means(KMeans(init=pca.components_, n_clusters=4, n_init=1,random_state=rstate), name=\"PCA-based\", data=data,labels=labels)\n",
    "    print(82 * '_')\n",
    "\n",
    "\n",
    "    print(\"kmeans++ Initialization\")\n",
    "    ypred=km1_km.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "    print(\"Random Initialization\")\n",
    "    ypred=km1_random.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))\n",
    "\n",
    "\n",
    "    print(\"PCA Components Initialization\")\n",
    "    ypred=km1_pca.predict(X_test)\n",
    "    print(classification_report(np.array(Y_test),ypred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
