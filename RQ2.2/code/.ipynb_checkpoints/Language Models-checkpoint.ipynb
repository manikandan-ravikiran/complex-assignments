{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Model- bert Folds: fold1\n",
      "------------------------------------------\n",
      "------------SVM----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.05172   0.09836        58\n",
      "           1    0.55200   0.76667   0.64186        90\n",
      "           2    0.20000   0.08333   0.11765        12\n",
      "           3    0.29412   0.62500   0.40000        24\n",
      "\n",
      "    accuracy                        0.47826       184\n",
      "   macro avg    0.51153   0.38168   0.31447       184\n",
      "weighted avg    0.63662   0.47826   0.40481       184\n",
      "\n",
      "------------XGB----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77419   0.41379   0.53933        58\n",
      "           1    0.59574   0.93333   0.72727        90\n",
      "           2    1.00000   0.08333   0.15385        12\n",
      "           3    0.27273   0.12500   0.17143        24\n",
      "\n",
      "    accuracy                        0.60870       184\n",
      "   macro avg    0.66067   0.38886   0.39797       184\n",
      "weighted avg    0.63623   0.60870   0.55813       184\n",
      "\n",
      "------------------------------------------\n",
      "Model- bert Folds: fold2\n",
      "------------------------------------------\n",
      "------------SVM----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76000   0.33929   0.46914        56\n",
      "           1    0.57778   0.86667   0.69333        90\n",
      "           2    0.30769   0.26667   0.28571        15\n",
      "           3    0.27273   0.13043   0.17647        23\n",
      "\n",
      "    accuracy                        0.56522       184\n",
      "   macro avg    0.47955   0.40076   0.40616       184\n",
      "weighted avg    0.57309   0.56522   0.52726       184\n",
      "\n",
      "------------XGB----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55263   0.37500   0.44681        56\n",
      "           1    0.59690   0.85556   0.70320        90\n",
      "           2    0.50000   0.06667   0.11765        15\n",
      "           3    0.33333   0.21739   0.26316        23\n",
      "\n",
      "    accuracy                        0.56522       184\n",
      "   macro avg    0.49572   0.37865   0.38270       184\n",
      "weighted avg    0.54258   0.56522   0.52243       184\n",
      "\n",
      "------------------------------------------\n",
      "Model- roberta Folds: fold1\n",
      "------------------------------------------\n",
      "------------SVM----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        58\n",
      "           1    0.00000   0.00000   0.00000        90\n",
      "           2    0.00000   0.00000   0.00000        12\n",
      "           3    0.13043   1.00000   0.23077        24\n",
      "\n",
      "    accuracy                        0.13043       184\n",
      "   macro avg    0.03261   0.25000   0.05769       184\n",
      "weighted avg    0.01701   0.13043   0.03010       184\n",
      "\n",
      "------------XGB----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.73333   0.37931   0.50000        58\n",
      "           1    0.55944   0.88889   0.68670        90\n",
      "           2    0.25000   0.08333   0.12500        12\n",
      "           3    0.42857   0.12500   0.19355        24\n",
      "\n",
      "    accuracy                        0.57609       184\n",
      "   macro avg    0.49284   0.36913   0.37631       184\n",
      "weighted avg    0.57700   0.57609   0.52689       184\n",
      "\n",
      "------------------------------------------\n",
      "Model- roberta Folds: fold2\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKANDAN\\Desktop\\dl2020-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------SVM----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80000   0.14286   0.24242        56\n",
      "           1    0.53289   0.90000   0.66942        90\n",
      "           2    0.00000   0.00000   0.00000        15\n",
      "           3    0.22727   0.21739   0.22222        23\n",
      "\n",
      "    accuracy                        0.51087       184\n",
      "   macro avg    0.39004   0.31506   0.28352       184\n",
      "weighted avg    0.53254   0.51087   0.42899       184\n",
      "\n",
      "------------XGB----------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.62500   0.35714   0.45455        56\n",
      "           1    0.56738   0.88889   0.69264        90\n",
      "           2    0.00000   0.00000   0.00000        15\n",
      "           3    0.27273   0.13043   0.17647        23\n",
      "\n",
      "    accuracy                        0.55978       184\n",
      "   macro avg    0.36628   0.34412   0.33091       184\n",
      "weighted avg    0.50183   0.55978   0.49919       184\n",
      "\n",
      "------------------------------------------\n",
      "Model- distill Folds: fold1\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKANDAN\\Desktop\\dl2020-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e1d7d554034b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mypred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dl2020-env\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dl2020-env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dl2020-env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dl2020-env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models=[\"bert\",\"roberta\",\"distill\",\"xlm\",\"xlnet\",\"xlmroberta\",\"albert\"]\n",
    "folds=[\"fold1\",\"fold2\"]\n",
    "majorfolder= \"../data/\"\n",
    "for mdl in models:\n",
    "    for fld in folds:\n",
    "        xtrain=pickle.load(open(majorfolder+mdl+\"/\"+fld+\"/\"+\"xtrain.pkl\",'rb'))\n",
    "        xtest=pickle.load(open(majorfolder+mdl+\"/\"+fld+\"/\"+\"xtest.pkl\",'rb'))\n",
    "        ytrain=pickle.load(open(majorfolder+mdl+\"/\"+fld+\"/\"+\"ytrain.pkl\",'rb'))\n",
    "        ytest=pickle.load(open(majorfolder+mdl+\"/\"+fld+\"/\"+\"ytest.pkl\",'rb'))\n",
    "        \n",
    "\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"Model-\",mdl,\"Folds:\",fld)\n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "        class_weights = list(class_weight.compute_class_weight('balanced',np.unique(ytrain),np.array(ytrain)))\n",
    "        w_array = np.ones(ytrain.shape[0], dtype = 'float')\n",
    "\n",
    "        for i, val in enumerate(ytrain):\n",
    "            w_array[i] = class_weights[val-1]\n",
    "\n",
    "        clf= SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=100, random_state=42,class_weight=\"balanced\",warm_start=True)\n",
    "        clf2=XGBClassifier(n_estimators=200,random_state=10,max_depth=3,learning_rate =0.1)\n",
    "\n",
    "        clf.fit(np.array(xtrain),np.array(ytrain).astype(np.int32))\n",
    "        clf2.fit(np.array(xtrain),np.array(ytrain).astype(np.int32))\n",
    "\n",
    "        ypred=clf.predict(xtest)\n",
    "        ypred2=clf2.predict(xtest)\n",
    "\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        print(\"------------SVM----------------------------------------------\")\n",
    "        print(classification_report(np.array(ytest).ravel(),ypred,digits=5))\n",
    "\n",
    "\n",
    "        print(\"------------XGB----------------------------------------------\")\n",
    "        print(classification_report(np.array(ytest).ravel(),ypred2,digits=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
