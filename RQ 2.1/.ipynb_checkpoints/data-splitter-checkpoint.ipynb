{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./data_kbai.tsv\",delimiter=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.text[df.groundtruth!=0].values\n",
    "Y=df.groundtruth[df.groundtruth!=0].values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groundtruth.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=labels\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ShuffleSplit,KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "loo = ShuffleSplit(n_splits=2,test_size=0.4,random_state=43)\n",
    "\n",
    "params=[]\n",
    "ypreds=[]\n",
    "train_indexes=[]\n",
    "test_indexes=[]\n",
    "ytests=[]\n",
    "for train_index, test_index in loo.split(X,Y):\n",
    "        parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=20, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "\n",
    "        gs_clf_svm = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "        gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "\n",
    "        ypred=gs_clf_svm.predict(X_test)\n",
    "        print(classification_report(y_test,ypred,digits=5,))\n",
    "        print(gs_clf_svm.best_score_)\n",
    "        print(gs_clf_svm.best_params_)\n",
    "        params.append(gs_clf_svm.best_params_)\n",
    "        train_indexes.append(train_index)\n",
    "        \n",
    "        test_indexes.append(test_index)\n",
    "        ypreds.append(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(len(ypreds)):\n",
    "    print(params[i])\n",
    "    print(confusion_matrix(Y[test_indexes[i]],ypreds[i]))\n",
    "    print(X[test_indexes[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.70000   0.36207   0.47727        58\n",
      "           2    0.61268   0.96667   0.75000        90\n",
      "           3    0.50000   0.08333   0.14286        12\n",
      "           4    0.50000   0.20833   0.29412        24\n",
      "\n",
      "    accuracy                        0.61957       184\n",
      "   macro avg    0.57817   0.40510   0.41606       184\n",
      "weighted avg    0.61816   0.61957   0.56497       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "traindata=pd.read_csv(\"./test1.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"./train1.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf', SGDClassifier(loss='log', penalty='l2',alpha=0.001, max_iter=100, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "ypred=clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,ypred,digits=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.58537   0.42857   0.49485        56\n",
      "           2    0.59677   0.82222   0.69159        90\n",
      "           3    0.00000   0.00000   0.00000        15\n",
      "           4    0.31579   0.26087   0.28571        23\n",
      "\n",
      "    accuracy                        0.56522       184\n",
      "   macro avg    0.37448   0.37792   0.36804       184\n",
      "weighted avg    0.50953   0.56522   0.52460       184\n",
      "\n",
      "Counter({2: 90, 1: 56, 4: 23, 3: 15})\n",
      "Counter({2: 140, 1: 71, 4: 43, 3: 22})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKANDAN\\Anaconda2\\envs\\dl-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "traindata=pd.read_csv(\"./train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"./test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "clf2 = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf', SGDClassifier(loss='log', penalty='l2',alpha=0.001, max_iter=100, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "\n",
    "clf2.fit(X_train,Y_train)\n",
    "ypred=clf2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,ypred,digits=5))\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(Y_test))\n",
    "print(Counter(Y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intepretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65385   0.60714   0.62963        56\n",
      "           1    0.62992   0.88889   0.73733        90\n",
      "           2    0.00000   0.00000   0.00000        15\n",
      "           3    0.66667   0.08696   0.15385        23\n",
      "\n",
      "    accuracy                        0.63043       184\n",
      "   macro avg    0.48761   0.39575   0.38020       184\n",
      "weighted avg    0.59044   0.63043   0.57151       184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55263   0.37500   0.44681        56\n",
      "           1    0.59690   0.85556   0.70320        90\n",
      "           2    0.50000   0.06667   0.11765        15\n",
      "           3    0.33333   0.21739   0.26316        23\n",
      "\n",
      "    accuracy                        0.56522       184\n",
      "   macro avg    0.49572   0.37865   0.38270       184\n",
      "weighted avg    0.54258   0.56522   0.52243       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xtrain=pickle.load(open('./xtrain.pkl', 'rb'))\n",
    "xtest=pickle.load(open('./xtest.pkl', 'rb'))\n",
    "\n",
    "ytrain=pickle.load(open('./ytrain.pkl', 'rb'))\n",
    "ytest=pickle.load(open('./ytest.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "traindata=pd.read_csv(\"./test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "traindata=pd.read_csv(\"./train2.tsv\",delimiter=\"\\t\")\n",
    "X_train=traindata.text.values\n",
    "Y_train=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "\n",
    "xtraindict={}\n",
    "\n",
    "\n",
    "for i,j in zip(X_train,xtrain):\n",
    "    xtraindict[i]=j\n",
    "\n",
    "for i,j in zip(X_test,xtest):\n",
    "    xtraindict[i]=j\n",
    "\n",
    "def returnfeatures(text):\n",
    "    global xtraindict\n",
    "    res=[]\n",
    "    for i in text:\n",
    "        res.append(xtraindict[i])\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "clf11 = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=200, random_state=42,class_weight=\"balanced\",warm_start=True)  #Pipeline([('custom', FunctionTransformer(returnfeatures)),('clf', SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=200, random_state=42,class_weight=\"balanced\",warm_start=True))])\n",
    "clf11.fit(np.array(xtrain),np.array(ytrain))\n",
    "ypred=clf11.predict(xtest)\n",
    "print(classification_report(ytest,ypred,digits=5))\n",
    "\n",
    "\n",
    "clf12=XGBClassifier(n_estimators=200,random_state=10,max_depth=3,learning_rate =0.1)\n",
    "clf12.fit(np.array(xtrain),np.array(ytrain))\n",
    "ypred=clf12.predict(xtest)\n",
    "print(classification_report(ytest,ypred,digits=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "te = TextExplainer(random_state=42)\n",
    "traindata=pd.read_csv(\"./test2.tsv\",delimiter=\"\\t\")\n",
    "X_test=traindata.text.values\n",
    "Y_test=np.array(traindata.label.values).astype(np.int32)\n",
    "\n",
    "X_test=np.array(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(X_test[i])\n",
    "    te.fit(X_test[i], clf11.predict_proba)\n",
    "    a=te.show_prediction(target_names=[1,2,3,4])\n",
    "    display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
